\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% IJCAI 2026 style
\usepackage{ijcai26}

% Recommended IJCAI packages
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage{multirow}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage[table]{xcolor}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{color}
\usepackage[switch]{lineno}

\usepackage{xcolor}
\newcommand\btext[1]{{\color{blue}{#1}}}

\linenumbers
\urlstyle{same}

\pdfinfo{
/TemplateVersion (IJCAI.2026.0)
}

% Theorem-like environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}

\newenvironment{problem}[1]
  {\vspace{\baselineskip}\noindent\textbf{Problem} (#1).\itshape}
  {\par}

% Title and authors (placeholders to be updated)
\title{SASS: Structure-Aware Surrogates for Learning to Schedule}

\author{Anonymous}
\begin{document}

\maketitle

\begin{abstract}
Task scheduling under uncertainty is a fundamental challenge in artificial intelligence and operations research, with applications in manufacturing, logistics, cloud computing, and healthcare.
Smart predict-and-optimize (SPO) aims to train predictors by minimizing downstream decision regret, but in scheduling this is challenging due to non-differentiable regret and the discrete, brittle dependence of optimal rules on predictions.
We focus on a class of \emph{surrogate-friendly scheduling problems} where the deterministic optimum is given by a known polynomial-time rule (e.g., SPT, Johnson's rule) that can be decomposed into a finite set of critical decisions (pairwise orderings, threshold tests, or group assignments).
We propose \emph{SASS}, a structure-aware surrogate training approach that replaces these discrete decisions with smooth sigmoid penalties and weights each penalty by the local impact of that decision on the scheduling objective.
The learned model is then \emph{plugged back} into the original polynomial-time rule at inference time.
We instantiate SASS for (i) single-machine scheduling with the sum of completion times (SCT) objective, and (ii) the two-machine flow shop with makespan minimization via Johnson's rule.
On synthetic benchmarks, SASS is substantially more stable than an SPO-based baseline under increasing noise and is competitive with predict-then-optimize (MSE) and learn-to-rank (LTR) baselines.
On a real-world outpatient scheduling dataset from a cancer hospital, SASS achieves the lowest relative SCT error in 11 out of 12 months and improves average error by 10--34\% over standard baselines.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Scheduling involves allocating limited resources to tasks over time to optimize objectives such as minimizing the sum of completion times (SCT), makespan, or weighted tardiness~\cite{baker2018principles,pinedo2022scheduling}.
It is a foundational problem in artificial intelligence and operations research, with applications in manufacturing, logistics, cloud computing, and healthcare.
Classical approaches typically assume that task parameters (e.g., processing times, release dates, due dates) are known and deterministic, enabling the use of efficient algorithms and priority rules such as SPT, EDD, FIFO, or Johnson's rule.
In reality, however, these parameters are uncertain and must be inferred from historical data.
This mismatch between deterministic models and stochastic environments motivates the development of data-driven decision-making methods that explicitly account for uncertainty in both prediction and optimization.

Smart predict-and-optimize (SPO) methods offer one such paradigm~\cite{elmachtoub2022smart}.
Rather than learning task parameters in isolation, SPO trains predictors to minimize \emph{decision regret}: the gap between the objective value achieved by decisions induced from predictions and the objective value of the optimal decision under the true parameters.
However, in scheduling, regret is typically non-differentiable and the mapping from predicted parameters to the optimal schedule can be discrete and brittle, which makes direct SPO training challenging.

We take a different route that is tailored to a class of \emph{surrogate-friendly scheduling problems}:
settings in which the deterministic optimum is given by a known polynomial-time rule and the rule itself reveals a small set of \emph{critical decisions} (e.g., pairwise precedence comparisons or group assignments) that determine the final schedule.
For this class, we propose \emph{SASS} (Structure-Aware Surrogate Scheduling): a problem-inspired surrogate loss that replaces each discrete critical decision by a smooth sigmoid penalty and weights that penalty by the decision's local impact on the scheduling objective (e.g., increase in SCT or makespan).
At inference time, we use the learned predictor inside the original polynomial-time rule, preserving interpretability and fast deployment.

We instantiate SASS for two classical problems where the deterministic optimum is known: (i) single-machine SCT minimization (SPT rule), and (ii) two-machine flow shop makespan minimization (Johnson's rule).
In both cases, the surrogate is decision-structured and objective-weighted, yielding stable gradients that focus learning on ambiguous and high-impact decisions.

To validate this positioning, we compare SASS against predict-then-optimize (MSE), a learn-to-rank baseline, and SPO+.
On synthetic instances, MSE may achieve lower average error in some regimes, but SASS is markedly more stable under increasing noise and consistently outperforms SPO+.
On a large-scale outpatient scheduling dataset from a cancer hospital, SASS achieves the lowest relative SCT error in 11 out of 12 months.

Our contributions can be summarized as follows:
\begin{enumerate}
    \item We introduce \emph{surrogate-friendly scheduling problems}, a class where the deterministic optimum is given by a known polynomial-time rule that decomposes into a finite set of critical decisions.
    \item For this class, we propose \emph{SASS}, a structure-aware, objective-weighted surrogate training approach that learns decision-relevant scores and plugs them into the original rule at inference time.
    \item We instantiate SASS on single-machine SCT minimization (SPT) and two-machine flow shop makespan minimization (Johnson), and evaluate on synthetic benchmarks and a real-world hospital scheduling dataset, demonstrating strong stability and improved performance over SPO+ in our settings.
\end{enumerate} The remainder of the paper is organized as follows.
Section~\ref{sec:framework} introduces our general predict-and-schedule framework.
Sections~\ref{sec:problem1} and~\ref{sec:flowshop} instantiate this framework for single-machine SCT minimization and two-machine flow shop makespan minimization, respectively.
Section~\ref{sec:evaluation} presents experimental results on synthetic benchmarks, followed by a real-world case study in patient scheduling in Section~\ref{sec:case_study}.
We discuss related work in Section~\ref{sec:related_work} and conclude in Section~\ref{sec:conclusion}.

\section{Surrogate-Based Predict-and-Schedule}
\label{sec:framework}

This section states the paper's core premise and positioning.
We focus on \emph{surrogate-friendly scheduling problems}: settings where (i) the
deterministic optimum is given by a known polynomial-time algorithm
$\mathcal{A}$, and (ii) $\mathcal{A}$ can be decomposed into a finite set of
\emph{critical decisions} (comparisons, threshold tests, group assignments) that
determine the schedule.
For this class, SASS replaces the discrete decisions of $\mathcal{A}$ with a
smooth, objective-weighted surrogate loss and then plugs the learned predictor
back into $\mathcal{A}$ at inference time.

\subsection{Problem Setting}

We consider a scheduling instance with $n$ jobs.
Each job $i$ has observed features $x_i \in \mathbb{R}^p$ and an unknown
parameter vector $\theta_i^\star$ (e.g., processing time, due date, or release
time).
Let $\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$ denote the
collection of true job parameters.
A schedule (or sequencing decision) is denoted by $\pi \in \Pi$, where $\Pi$
is the set of feasible schedules for the environment under study.
The resulting objective value under the true parameters is $C(\pi;\theta^\star)$,
where $C$ may represent, for example, sum of completion times or makespan.

The learning task is to learn a predictor $\hat{\theta}=f_\omega(x)$ (with
parameters $\omega$) that yields good schedules under the downstream objective.
In an SPO view, one would minimize the regret of using $\pi(\hat{\theta})$ instead of the
optimal solution, namely
\begin{equation}
\label{eq:regret-general}
R(\hat{\theta},\theta^\star)
:=
C(\pi(\hat{\theta});\theta^\star)
-
C(\pi(\theta^\star);\theta^\star),
\end{equation}
which is generally non-differentiable with respect to~$\omega$.
SASS does not attempt to optimize~\eqref{eq:regret-general} directly.
Instead, it constructs a differentiable surrogate by exploiting the decision structure of $\mathcal{A}$.

\noindent\textbf{Step 1: Choose prediction targets (parameters or decision-relevant scores).}
For each job $i$, define the unknown parameter vector $\theta_i^\star$ governing
its contribution to the optimization problem (e.g., processing times, due dates,
or machine-dependent durations).
Let a dataset
$\mathcal{D}=\{(x_j,\theta_j^\star)\}_{j=1}^N$ be given, consisting of past
observations from which a predictor $f_\omega$ can be trained.
In some problems, it is convenient for $f_\omega$ to predict not the raw
parameters $\theta$ directly, but a set of \emph{decision-relevant scores} that
parameterize the critical decisions of the deterministic algorithm (Step~2).

\noindent\textbf{Step 2: Specify the deterministic optimal rule and its critical decisions.}
Many scheduling problems become tractable when $\theta^\star$ is known.
Suppose that, for known parameters $\theta$, the deterministic variant admits a
polynomial-time algorithm $\mathcal{A}$ that returns an optimal decision:
\[
\pi(\theta) = \mathcal{A}(\theta).
\]
Examples include single-machine scheduling problems where sorting rules are optimal, and
two-machine flow shops solved by Johnson’s rule, two problems which we tackle in this paper.
Such algorithms typically reveal a structural decomposition
$\mathcal{A}(\theta)$ that induces partitions, rankings, or threshold decisions.
This structure is key for constructing differentiable surrogates.

\noindent\textbf{Step 3: Build an objective-weighted, smooth surrogate.}
The deterministic algorithm $\mathcal{A}$ induces a discrete mapping from
parameters~$\theta$ to decisions~$\pi$.
SASS replaces this mapping with a differentiable surrogate loss that mirrors the critical decisions of $\mathcal{A}$ and weights errors by their objective impact.
Compared to treating the optimization oracle as a black box, this ``white-box'' construction yields simpler gradients and avoids repeatedly solving a hard optimization problem during training.
The construction follows three ingredients:

\paragraph{(a) Critical decisions.}
Let $\mathcal{A}$ determine a schedule through a finite set of \emph{critical
decisions} $\mathcal{K}$, such as:
(i) pairwise precedence comparisons (e.g., SPT/EDD/FIFO-style ordering
decisions), (ii) threshold tests, or (iii) group assignments (e.g., Johnson's
partition into two groups).
Some rules in $\mathcal{K}$
are per-job classification decisions, while others are pairwise job comparisons.

\paragraph{(b) Oriented margins and sigmoid penalties.}
For each critical decision $d \in \mathcal{K}$, define a signed \emph{decision
score} $s_d(\omega;x)$ produced by the predictor, such that the sign of
$s_d$ encodes the model's preferred outcome for $d$ (e.g., ``$i$ before $j$'').
We then replace the hard, non-differentiable decision indicator by a smooth
sigmoid approximation.
To ensure the surrogate penalizes the \emph{wrong} outcome (rather than
encouraging a fixed sign), we orient each decision score using the true
parameters.
Specifically, define a \emph{signed correctness margin}
$m_d(\omega;x,\theta^\star)$ such that $m_d>0$ when the model agrees with the
ground-truth decision for $d$ (with margin) and $m_d<0$ otherwise.
Equivalently, $m_d$ is $s_d$ multiplied by the label induced by $\theta^\star$, so that the correct side of the decision boundary corresponds to $m_d>0$.
We then use the smooth misclassification indicator
\[
\sigma\!\left( -\frac{m_d(\omega;x,\theta^\star)}{\lambda} \right),
\]
where $\lambda>0$ controls sharpness around the boundary, $s_d=0$.

\paragraph{(c) Objective-weighted aggregation.}
The surrogate loss is assembled as a weighted sum over critical decisions:
\begin{equation}
\label{eq:general-surrogate}
L_{\mathrm{surr}}(\omega)
:=
\sum_{d \in \mathcal{K}}
\phi_d(\theta^\star)\,
\sigma\!\left(
\frac{-m_d(\omega;x,\theta^\star)}{\lambda}
\right),
\end{equation}
where $\phi_d(\theta^\star)\ge 0$ measures the impact of deciding $d$ incorrectly
on the scheduling objective (e.g., SCT increase or makespan increase).
As $\lambda \to 0$, the surrogate approaches a hard penalty on incorrect
decisions, while for $\lambda>0$ it remains smooth and trainable with gradient
descent.
Key properties of this surrogate, including differentiability and convergence to regret, are analyzed in the Technical Appendix.

\noindent\textbf{Step 4: Train and deploy via the original rule.}
The neural network $f_\omega$ is trained by minimizing the surrogate loss:
\[
\omega^\star
:= 
\arg\min_{\omega}
L_{\mathrm{surr}}(\omega).
\]
At inference time, the model produces either predicted parameters
$\hat{\theta}=f_{\omega^\star}(x)$ or decision-relevant scores that determine
the critical decisions; these are passed into the polynomial-time algorithm:
\[
\hat{\pi}
:=
\mathcal{A}(\hat{\theta}).
\]
In this paper, we focus on scheduling and instantiate this framework for two
settings where $\mathcal{A}$ is known and optimal.


\subsection{Running Example: Outpatient Scheduling}
\label{sec:framework-running-example}
Consider a stylized outpatient clinic with a single exam doctor.
Patients $i=1,\dots,n$ arrive randomly with known appointment times and
uncertain exam durations.
Depending on the operational objective, a deterministic policy might implement
FIFO (serve in order of arrival), an EDD-like rule (serve those with earlier appointment times first), or 
an SPT-like rule (serve those with shorter predicted exams
first) as a proxy for minimizing waiting or completion-time objectives.

In this setting, a critical decision could be a precedence relation (``serve
patient $i$ before patient $j$''), but it could also be a per-patient
classification decision (``patient $i$ belongs to the short-visit group''),
depending on the scheduling rule used.
The surrogate in Eq.~\eqref{eq:general-surrogate} penalizes incorrect or ambiguous
decisions through $\sigma(-m_d/\lambda)$ and uses $\phi_d(\theta^\star)$ to reflect
their downstream impact (e.g., increase in total waiting time or SCT).
This connects directly to the hospital case study in
Section~\ref{sec:case_study}, where our learning objective is designed to
improve the resulting patient sequencing rather than pointwise duration
accuracy.

\section{Problem 1: Single-Machine Scheduling}
\label{sec:problem1}
We now instantiate the four-step framework of Section~\ref{sec:framework} for the
single-machine sum of completion times (SCT) objective, where the processing times are unknown.
The deterministic counterpart is solved by the shortest-processing-time (SPT)
rule; we derive a smooth, decision-level surrogate that targets the pairwise
precedence decisions induced by SPT and weights each potential misordering by
its SCT impact.

\noindent\textbf{Step 1: Identify Unknown Parameters.}
In this problem, the unknown parameter for each task $i$ is its processing time
$y_i>0$. In the notation of Section~\ref{sec:framework}, we write
$\theta_i^\star := y_i$ and $\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$.
We observe features $x_i\in\mathbb{R}^p$ and learn a predictor
$\hat{\theta}_i = f_\omega(x_i)$ from a dataset
$\mathcal{D} = \{(x_j, \theta_j^\star)\}_{j=1}^N$ (equivalently, $\hat{y}_i=\hat{\theta}_i$).

\noindent\textbf{Step 2: Deterministic Polynomial-Time Counterpart.} We consider the following single-resource scheduling setting: a resource is assigned to process $n$ tasks (e.g., jobs scheduled for a given day).
All $n$ tasks are assumed to be available at the beginning of the scheduling period, but their processing times are unknown.
The resource is non-idling, working continuously until all tasks are completed.
The objective is to find a task sequencing that minimizes the sum of completion times (SCT).
When the true durations $y_1, \ldots, y_n$ are known, the optimal sequence follows the shortest processing time first (SPT) heuristic, arranging tasks in ascending order of their durations~\cite{pinedo2022scheduling}.
Equivalently, letting $\theta=(\theta_1,\dots,\theta_n)$ denote processing
times, the deterministic algorithm is
\(
\pi(\theta)=\mathcal{A}_{\mathrm{SPT}}(\theta)
\),
where $\mathcal{A}_{\mathrm{SPT}}$ sorts tasks by increasing $\theta_i$.

A straightforward approach is the predict-then-optimize paradigm~\cite{Mandi2020},
in which $f_\omega$ is learned by minimizing empirical mean squared error (MSE):
\begin{equation}
\omega^\star_{\mathrm{MSE}}
=
\arg\min_{\omega} \sum_{j=1}^{N} \bigl(f_\omega(x_j) - y_j\bigr)^2,
\end{equation}
The resulting model predicts durations $\hat{y}_i=f_{\omega^\star_{\mathrm{MSE}}}(x_i)$,
and the optimization phase schedules tasks by sorting predicted durations (SPT).
In Section~\ref{sec:framework} notation, this corresponds to computing
$\hat{\theta}_i=f_{\omega^\star_{\mathrm{MSE}}}(x_i)$ and then
$\hat{\pi}=\mathcal{A}_{\mathrm{SPT}}(\hat{\theta})$.

However, minimizing MSE ignores the structure of the scheduling objective.
For SCT, the cost of a prediction error depends entirely on whether it alters the task sequence.
Consider a sequencing where the task in position $k$ has duration $y_k$. The total SCT is $\sum_{k=1}^n (n+1-k) \, y_k$.
Swapping two tasks at positions $i < j$ alters the objective by:
\begin{align}
R_{i,j} &= \big[(n{+}1{-}i)\, y_j + (n{+}1{-}j)\, y_i\big] -\\
&- \big[(n{+}1{-}i)\, y_i + (n{+}1{-}j)\, y_j\big] \nonumber \\
       &= (j - i)(y_j - y_i).
\end{align}
We therefore seek to minimize the \emph{decision regret}, defined as the total cost of all misordered pairs.

\begin{problem}{Regret minimization in SCT} \label{prob:problem1}
Find $f_\omega$ that minimizes:
\begin{equation} \label{eq:smartsched}
L_{\text{regret}} = \sum_{\substack{\theta_i^\star < \theta_j^\star}} R_{i,j} \cdot \max(0, \text{sign}(f_\omega(x_i) - f_\omega(x_j))).
\end{equation}
\end{problem} Directly optimizing $L_{\text{regret}}$ is challenging due to non-differentiability and the combinatorial nature of ordering tasks~\cite{elmachtoub2022smart}.
We therefore derive a differentiable surrogate loss that targets the critical
pairwise precedence decisions of SPT and weights each decision by its SCT
impact.

\noindent\textbf{Step 3: Derive a Smooth Surrogate from SPT.}  The critical decisions for SPT are pairwise precedence comparisons.
For a pair $(i,j)$, define the decision score
\(
s_{i,j}(\omega;x)= \hat{\theta}_i-\hat{\theta}_j = f_\omega(x_i)-f_\omega(x_j)
\),
whose sign encodes the model's preference.
When $\theta_i^\star<\theta_j^\star$ (i.e., $y_i<y_j$), the correct order is
$i$ before $j$, and a misordering occurs
when $s_{i,j}(\omega;x)>0$.
In the framework notation, take $\mathcal{K}=\{d=(i,j): i<j\}$, $s_d=s_{i,j}$,
and orient by the ground truth:
\(
m_d(\omega;x,\theta^\star)=-s_{i,j}(\omega;x)
\)
for $\theta_i^\star<\theta_j^\star$, so $m_d>0$ iff the order is correct.
With $\phi_d(\theta^\star)=R_{i,j}$, Eq.~\eqref{eq:general-surrogate} gives the term
$R_{i,j}\sigma(s_{i,j}/\lambda)$.
The empirical sigmoid loss is thus defined as:
\begin{equation}
L_{\text{sigmoid}}
\;=\;
\sum_{\substack{\theta_i^\star < \theta_j^\star}}
  R_{i,j}\,
  \sigma\!\Bigl( \tfrac{f_\omega(x_i) - f_\omega(x_j)}{\lambda} \Bigr),
\end{equation} A larger \(\lambda\) smooths transitions, while a smaller \(\lambda\) sharpens sensitivity to misorderings.

By minimizing the empirical sigmoid loss, the learned model \(f_\omega\) is encouraged to satisfy \(f_\omega(x_j) > f_\omega(x_i)\) whenever \(\theta_j^\star > \theta_i^\star\).
Formally:
\[
\omega^\star
\;=\;
\arg\min_{\omega}
  L_{\text{sigmoid}}(\omega),
\]
Thus, training adjusts \(f_\omega\) to minimize the number and severity of misordered pairs, aligning predictions with true task durations.
When \(f_\omega\) preserves correct orderings, the sigmoid term remains near zero, driving \(L_{\text{sigmoid}}\) downward.

\noindent\textbf{Step 4: Train and Infer with SPT.} At inference time, given a new instance with features $\{x_i\}_{i=1}^n$, we
compute $\hat{\theta}_i=f_{\omega^\star}(x_i)$ and return
$\hat{\pi}=\mathcal{A}_{\mathrm{SPT}}(\hat{\theta})$, i.e., the SPT schedule
obtained by sorting tasks by $\hat{\theta}_i$ in ascending order.

\section{Problem 2: Flow Shop Scheduling}
\label{sec:flowshop}

The surrogate framework developed in Section~\ref{sec:framework} naturally extends
to other scheduling problems whose optimal deterministic policies admit rule-based
structural characterizations.
In this section, we demonstrate this by considering
the classical two-machine flow shop scheduling problem with makespan minimization,
denoted $F2\|C_{\max}$, for which the optimal policy is given by Johnson’s rule.
However, we consider the case where the processing times on the two machines are unknown. 
We show how to construct a smooth surrogate loss that mimics the structure of
the optimal rule while remaining differentiable and suitable for gradient-based
learning.

\noindent\textbf{Step 1: Identify Unknown Parameters.}
In the $F2\|C_{\max}$ setting, the unknown parameters for each job $i$ are its
two processing times on machines $1$ and $2$. In the notation of
Section~\ref{sec:framework}, let
$\theta_i^\star := (p_{i1},p_{i2})$ and
$\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$.

\noindent\textbf{Step 2: Deterministic Polynomial-Time Counterpart.} In the $F2\|C_{\max}$ setting, each job $i$ has two true processing times 
$(p_{i1}, p_{i2})$, one for each machine.
Johnson’s rule partitions all jobs into
two sets:
\[
G_1 = \{ i : p_{i1} < p_{i2} \}, 
\qquad
G_2 = \{ i : p_{i1} \ge p_{i2} \},
\]
orders $G_1$ in ascending $p_{i1}$, orders $G_2$ in descending $p_{i2}$, and 
concatenates the two sequences.
Consequently, the optimal sequence is determined
by (i) the correct group assignment of each job and (ii) the correct ordering 
within each group.
Equivalently, for known processing times $\theta$, the deterministic optimum is
\(
\pi(\theta)=\mathcal{A}_{\mathrm{J}}(\theta)
\),
where $\mathcal{A}_{\mathrm{J}}$ is Johnson's rule.

When processing times are unknown and must be predicted from features $x_i$, we
follow the Section~\ref{sec:framework} view and predict \emph{decision-relevant
scores} that parameterize the critical decisions of $\mathcal{A}_{\mathrm{J}}$.
Concretely, each job $i$ is mapped to two scalar scores
\[
(\hat{d}_i, \hat{s}_i) = f_\omega(x_i)=:\hat{\theta}_i,
\]
where $\hat{d}_i \in \mathbb{R}$ is a \emph{group score} indicating whether the
job should belong to $G_1$ or $G_2$, and $\hat{s}_i \in \mathbb{R}$ is a
\emph{sortable score} used to determine the job’s relative position \emph{within}
its assigned group.
The predicted sequence then follows the structure of Johnson’s rule:
\begin{enumerate}
    \item Assign each job to $\hat{G}_1$ if $\hat{d}_i < 0$ and to $\hat{G}_2$ otherwise.
    \item Sort $\hat{G}_1$ by increasing $\hat{s}_i$.
    \item Sort $\hat{G}_2$ by decreasing $\hat{s}_i$.
\end{enumerate}

This parameterization separates the discrete grouping decision from the within-group ranking
decision, reflecting the decomposition inherent in Johnson’s optimal policy.
At inference time, we apply the same deterministic structure,
$\hat{\pi}=\mathcal{A}_{\mathrm{J}}(\hat{\theta})$, using $\hat{\theta}_i=(\hat{d}_i,\hat{s}_i)$.

\noindent\textbf{Step 3: Derive a Smooth Surrogate from Johnson's Rule.} To train the model, we define a smooth surrogate loss consisting of two components:
(1) a penalty for incorrect \emph{group assignment}, and
(2) a penalty for incorrect \emph{within-group ordering}.
Both components rely on sigmoidal approximations of indicator functions, as in
Section~\ref{sec:framework}. 

Let $\mathcal{K}=\mathcal{K}_{\mathrm{group}}\cup\mathcal{K}_{\mathrm{order}}$
with group decisions $d=i$ and ordering decisions $d=(i,j)$.
For $d=i$, set $s_d=\hat{d}_i$, $m_d=\hat{d}_i d_i$ with $d_i=p_{i1}-p_{i2}$, and
$\phi_d=|d_i|$.
For $d=(i,j)$, set $\phi_d=\Delta_{i,j}$ and use sortable scores:
in $G_1$ (true $p_{i1}<p_{j1}$) take $s_d=\hat{s}_i-\hat{s}_j$ and $m_d=-s_d$;
in $G_2$ (true $p_{i1}>p_{j1}$) take $s_d=\hat{s}_j-\hat{s}_i$ and $m_d=-s_d$.
Then each term in $L_{\mathrm{group}}$ and $L_{\mathrm{order}}$ matches
Eq.~\eqref{eq:general-surrogate}.

\paragraph{Group assignment surrogate.}
For each job $i$, the true group indicator satisfies
\[
d_i = p_{i1} - p_{i2},
\qquad
i \in G_1 \iff d_i < 0.
\]
Incorrect assignment occurs when the predicted sign of $\hat{d}_i$ differs from the
true sign of $d_i$.
We define the group surrogate loss as,
\begin{equation}
L_{\mathrm{group}}
:= 
\sum_{i} 
\phi_i \,
\sigma\!\left( -\frac{\hat{d}_i\, d_i}{\lambda} \right),
\label{eq:group-loss}
\end{equation}
where $\sigma$ is the sigmoid function, $\lambda>0$ controls smoothness, and
$\phi_i = |d_i|$ weights mistakes according to the severity of misclassification
(the farther a job is from the decision boundary $p_{i1} = p_{i2}$, the more 
important it is to assign it correctly).
The term in~\eqref{eq:group-loss} is
small when $\hat{d}_i$ has the correct sign with sufficient margin, and close to
1 otherwise.

\paragraph{Within-group surrogate.}
Conditioned on correct group membership, the regret of the flow shop policy arises
from misordering jobs within $G_1$ or $G_2$.
For two jobs $i,j$:
\begin{itemize}
    \item If $i,j \in G_1$ and $p_{i1} < p_{j1}$, then $i$ should precede $j$.
    \item If $i,j \in G_2$ and $p_{i2} > p_{j2}$, then $i$ should precede $j$.
\end{itemize}
To align the surrogate with makespan regret, we weight each potential swap by
its impact on completion time.
For two jobs $i$ and $j$ on machines $1$ and $2$, let
\begin{equation}
T_{i,j} = p_{i1} + \max(p_{i2},p_{j1}) + p_{j2},
\end{equation}
\begin{equation}
T_{j,i} = p_{j1} + \max(p_{j2},p_{i1}) + p_{i2},
\end{equation}
and define the incremental cost of placing $j$ before $i$ instead of the
correct order as
\begin{equation}
\Delta_{i,j} = T_{j,i} - T_{i,j}.
\end{equation}
We then set the within-group surrogate to
\begin{equation}
\label{eq:order-loss}
\resizebox{0.95\linewidth}{!}{$
\displaystyle
L_{\mathrm{order}}
:=
\sum_{\substack{i,j \in G_1 \\ p_{i1} < p_{j1}}}
\Delta_{i,j}\, \sigma\!\Big( \tfrac{\hat{s}_i - \hat{s}_j}{\lambda} \Big)
 +
\sum_{\substack{i,j \in G_2 \\ p_{i2} > p_{j2}}}
\Delta_{i,j}\, \sigma\!\Big( \tfrac{\hat{s}_j - \hat{s}_i}{\lambda} \Big)
$}\,.
\end{equation}
As in the SCT surrogate, the sigmoid penalizes misordered pairs (i.e., cases where
$\hat{s}_i > \hat{s}_j$ despite $i$ being correctly ordered before $j$), with 
penalties scaled by the corresponding increase in makespan $\Delta_{i,j}$.

\paragraph{Combined surrogate and properties.}
The full surrogate loss for Johnson’s rule is the simple additive combination
of group and ordering components:
\begin{equation}
\label{eq:johnson-loss}
L_{\mathrm{Johnson}}
:=
L_{\mathrm{group}}
+
L_{\mathrm{order}}.
\end{equation}
By construction, $L_{\mathrm{Johnson}}$ is infinitely differentiable in the
network parameters, and jobs whose misclassification or misordering has a
larger impact on the makespan (larger $|d_i|$ or $\Delta_{i,j}$) receive
larger weights.
As $\lambda \to 0$, the sigmoids in~\eqref{eq:group-loss} and
~\eqref{eq:order-loss} approach hard indicators of incorrect group assignment
and within-group ordering, so that $L_{\mathrm{Johnson}}$ converges to a
piecewise-constant approximation of the true makespan regret induced by
Johnson's rule.

\noindent\textbf{Step 4: Train and Infer with Johnson's Rule.}
We train $f_\omega$ by minimizing the surrogate $L_{\mathrm{Johnson}}$.
At inference time, given a new instance with features $\{x_i\}_{i=1}^n$, we
compute $(\hat{d}_i,\hat{s}_i)=f_{\omega^\star}(x_i)$ and construct the schedule
using the three-step Johnson-style procedure above (partition into
$\hat{G}_1,\hat{G}_2$, sort within each group, then concatenate).


\section{Evaluation}
\label{sec:evaluation}

This section details the empirical evaluation on synthetic datasets of the proposed approach for the single-machine SCT problem (Problem~1) and the Flow Shop Scheduling problem (Problem~2).
We first describe the experimental setup, including dataset generation, benchmark methods, implementation details, and evaluation metrics.
Next, we outline the experimental procedure for solving the scheduling problem and compare our method against existing baselines.
Finally, we present the main experimental results and discuss the applicability and scalability of our approach.

\subsection{Experimental Setup}

Experiments were conducted on synthetically generated datasets to evaluate the performance of the proposed SASS surrogate loss under a range of scheduling scenarios.
The experiments systematically varied data generation models, noise levels, uncertainty level on task duration, and benchmark comparisons.

\paragraph{Datasets.}

We constructed two synthetic datasets using linear and nonlinear functions to simulate varying complexity levels.
This setup offers full control over noise and duration variability, allowing us to isolate the effect of surrogate loss choice.
In the absence of established benchmarks, these two datasets support systematic evaluation.
\begin{itemize}
    \item \textbf{Problem 1 (SCT) Generation.} We generate job durations using linear and nonlinear functions:
    \begin{itemize}
        \item \emph{Linear model:} \( f(x) = \mathbf{xw} \), where \(\mathbf{w}\) is a randomly generated weight vector, and \(\mathbf{x}\) consists of features uniformly sampled from \([0, 1]\).
        \item \emph{Nonlinear model:} A nonlinear combination is computed as:
        \[
        g(x) = 3x_1^2 + 4.0\sin(2\pi x_2) + 3x_3x_4 + 2x_5^3,
        \]
        where \(x_1, \dots, x_5\) are uniformly sampled features.
        This specific structure introduces smooth nonlinearities, feature interactions, and periodic components.
    \end{itemize}

    \item \textbf{Problem 2 (Flow Shop) Generation.} We generate durations for two machines, $m_1$ and $m_2$:
    \begin{itemize}
        \item \emph{Linear model:} Generated similarly to Problem 1. \todo[inline]{to fix as for NonLinear}
        \item \emph{Nonlinear model:} To ensure a balanced probability of assigning jobs to groups $G_1$ and $G_2$ (see Section~\ref{sec:flowshop}), we use the function $g(\mathbf{x})$ defined above:
        \[
        \begin{aligned}
        m_1(\mathbf{x}) &= g(\mathbf{x}) + 0.3\, x_1 - 0.2\, x_3, \\
        m_2(\mathbf{x}) &= g(\mathbf{x}) - 0.25\, x_2 + 0.4\, x_4 .
        \end{aligned}
        \]
    \end{itemize}
\end{itemize} The functions were chosen to ensure that the learning task remains nontrivial, requiring the model to capture both local and global feature dependencies, while still being interpretable and reproducible.

To ensure strictly positive durations, constants of $100$ and $500$ were added to the final task durations for the Problem~1 and Problem~2 datasets, respectively. Finally, gaussian noise with standard deviation $\eta$ was added to simulate uncertainty.

\paragraph{Benchmark methods.}

For both Problem configurations, we compare our method with a \emph{predict-and-optimize} solution via MSE and other two \emph{Smart Predict, then Optimize} baselines.
\emph{SPO+}~\cite{elmachtoub2022smart} is a specific SPO implementation that uses a convex surrogate loss to train the model to minimize decision regret. In contrast, the \emph{logistic rank loss} is an LTR surrogate that penalizes incorrect pairwise orderings based on their differences, without relying on the specifics of the scheduling problem.
%\footnote{For each job pair $(i,j)$ where $i$ precedes $j$, we define the surrogate loss as $\sigma(\Delta_{ij})$, where $\Delta_{ij} = f_\omega(x_i) - f_\omega(x_j)$; this applies to both Problem~1 and Problem~2.} to put in appendix

\paragraph{Experimental Procedure.}
\label{sec:experimental_procedure}
To enable scalability across scheduling problems of arbitrary size, we train a predictive model that is independent of the number of jobs in the input. This is achieved by formulating the learning objective in a pairwise manner, which allows the model to be trained on comparisons between two jobs and then generalizes to schedules of any length. Exhaustively comparing all possible pairwise job combinations in the training set is computationally infeasible; therefore, we adopt an approximation strategy based on sampling a subset of job pairs. Despite this approximation, Figure~\ref{fig:pairwise_number} shows that a subset of job pairs can already achieve a low SCT error compared to the optimal solution, without training on all possible pairwise comparisons. In fact, using $10000$ pairwise comparisons is already enough to reach a 3.2\% error relative to the optimal total SCT.
    
    
\begin{figure}[t]
\centering
\includegraphics[width=0.45\textwidth]{new_plot/analysis_number_of_pairs_2.png}
\caption{Impact of the number of sampled pairs on performance on \emph{Nonlinear} dataset.}
\label{fig:pairwise_number}
\end{figure}


For MSE, LTR and our method we use the same two-hidden-layer neural network architecture, number of iterations and, finally, number of pair comparisons, to properly evaluate which of them converges first to a low error. For SPO+, we use a dedicated hyperparameter optimization procedure (e.g., batch size) and a larger number of iterations where needed. Code will be available upon acceptance.
Each dataset is normalized and split into 70\% training, 10\% validation, and 20\% test subsets, with training performed using the Adam optimizer and early stopping.


\paragraph{Evaluation metric.}
Models are evaluated on the full test set by comparing the SCT and Makespan of jobs ordering defined from the predicted durations of each activity within a job, against the optimal solution computed using the true durations. The optimal schedule corresponds to the SPT rule for Problem~1 and the Johnson schedule for Problem~2.


\subsection{Results}



\begin{table}[t]
\centering
\resizebox{0.85\columnwidth}{!}{
\begin{tabular}{lcccc}
\toprule
\textbf{Method} & \multicolumn{4}{c}{\textbf{Dataset Size}} \\
                 & 5000 & 10000 & 50000 & 100000 \\
\midrule
MSE         & 2.79s & 2.71s & 9.68s & 21.62s \\
LTR   & 25.12s & 30.81s & 35.79s & 45.05s \\
SASS (ours) & 28.64s & 33.26s & 41.57s & 52.59s \\
SPO+        & 26.15s & 59.82s & 23.746s & 24.246s \\
\bottomrule
\end{tabular}}
\caption{Training times across different nonlinear dataset sizes with noise $10$, computed over $10$ runs.}
\label{tab:times_training}
\end{table}

Table~\ref{tab:times_training} reports the training times for different nonlinear dataset sizes with noise level $5$. As observed, the fastest method is MSE, but it grows roughly with the dataset size since it compares all elements. In contrast, LTR and SASS (ours) scale more smoothly thanks to pairwise approximation (Section~\ref{sec:experimental_procedure}).
Regarding SPO+, we observe that its training time is independent of the dataset size but depends on the specific problem instance and, consequently, on the gradient of the problem. Additionally, SPO+ requires hyperparameter optimization, taking roughly 40 minutes per dataset and noise level, to achieve comparable performance, and it typically needs $5000$ iterations instead of the $1000$ used by the other methods.

\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{new_plot/nonLinear_problem1.png}
\caption{Comparison of SPO+, Rank Loss, and the proposed surrogate method on \emph{Nonlinear} datasets of size $10000$. SCT error (logarithmic scale) relative to the optimal schedule is shown.}
\label{fig:nonLinear_dataset_1_machine_problem}
\end{figure}

\begin{table}[t]
\centering
\resizebox{0.45\textwidth}{!}{
\begin{tabular}{lcccccc}
\toprule
\textbf{Loss} & \multicolumn{6}{c}{\textbf{Noise Level}} \\
              & 0 & 2 & 4 & 6 & 8 & 10 \\
\midrule
MSE Loss     & 0.576 & 0.363 & 0.359 & 0.701 & 0.706 & 1.132 \\
Rank Loss    & 0.225 & 0.284 & 0.356 & 0.494 & 0.647 & 0.976 \\
SASS (ours)  & \textbf{0.209} & \textbf{0.222} & \textbf{0.270} & \textbf{0.402} & \textbf{0.622} & \textbf{0.954} \\
SPO+         & 2.262 & 2.445 & 6.125 & 6.450 & 8.589 & 6.178 \\
\bottomrule
\end{tabular}}
\caption{SCT error across different noise level $\eta$ over linear dataset with size $10000$.}
\label{tab:loss_means}
\end{table}





\section{Case Study: Patient Scheduling}
\label{sec:case_study}

We evaluate the proposed SASS surrogate loss on a real-world dataset
from \textit{DayHospital}, a U.S.\ cancer clinic. We describe the setting,
experimental protocol, and results.

\subsection{Case Description and Setup}

We evaluate our method on real-world data from \textit{DayHospital}, a U.S.\ cancer clinic. The problem is to sequence patient exams to minimize congestion (SCT), where appointment times are known but exam durations are uncertain.
The dataset spans two months (January and November 2021) and contains approximately 201,000 patient pathways derived from RTLS traces.
For each exam, we extract a feature vector $\mathbf{x}_i$ comprising
the exam location, scheduled time, department, scheduled duration,
diagnosis, appointment type, and a linkage indicator for subsequent infusions.
To simulate deployment, we use a rolling-horizon split, training on the first three weeks of each month and evaluating on the fourth.


We compare SASS against three baselines: (i) \emph{Rank Loss} (pairwise negative log-likelihood), (ii) \emph{Mean Squared Error (MSE)} (predict-then-optimize), and (iii) \emph{SPO+} (a convex decision-aware surrogate).
All models are two-layer feedforward neural networks trained with Adam.
Performance is measured by the \emph{relative SCT error}, defined as the normalized difference between the SCT of the predicted schedule and the optimal SCT under true durations.

\subsection{Results}

Table~\ref{tab:monthly-sct} reports the relative SCT error across the full year (January--December 2021).
SASS achieves the lowest error in 11 out of 12 months, with an average error of \textbf{0.316}, compared to 0.353 for MSE, 0.338 for LTR, and 0.476 for SPO+.

\begin{table}[t]
\centering
\caption{Final relative SCT errors across months of 2021 for each method.
Average values: SPO+= 0.476, LTR= 0.338, MSE= 0.353, and SASS (ours)= \textbf{0.316}.}
\label{tab:monthly-sct}
\begin{tabular}{lcccccc}
\toprule
Method & Jan & Feb & Mar & Apr & May & Jun \\
\midrule
SPO+        & 0.48 & 0.56 & 0.53 & 0.53 & 0.52 & 0.42 \\
LTR         & 0.33 & 0.36 & 0.33 & 0.35 & 0.33 & 0.33 \\
MSE         & 0.35 & 0.38 & 0.36 & 0.35 & 0.34 & 0.34 \\
SASS (ours) & \textbf{0.31} & \textbf{0.34} & \textbf{0.33} & \textbf{0.33} & \textbf{0.30} & \textbf{0.31} \\
\midrule
Method & Jul & Aug & Sep & Oct & Nov & Dec \\
\midrule
SPO+        & 0.48 & 0.38 & 0.40 & 0.49 & 0.42 & 0.50 \\
LTR         & 0.33 & \textbf{0.28} & 0.34 & 0.32 & 0.37 & 0.38 \\
MSE         & 0.33 & 0.31 & 0.34 & 0.36 & 0.37 & 0.41 \\
SASS (ours) & \textbf{0.30} & 0.29 & \textbf{0.31} & \textbf{0.29} & \textbf{0.33} & \textbf{0.35} \\
\bottomrule
\end{tabular}
\end{table}

Figure~\ref{fig:real-data-jan} shows the training trajectory for a representative month (January). Our approach consistently converges to a lower, and more stable error, confirming that weighting decision errors by their specific SCT impact yields significant gains over general ranking or regression objectives.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{LossComparison_Jan.png}
    \caption{Relative SCT error during training on the real-world Exam scheduling dataset for January 2021.
    The SASS surrogate loss consistently achieves lower SCT error compared to Rank Loss, MSE Loss, and SPO+.}
    \label{fig:real-data-jan}
\end{figure}



\section{Related Work}
\label{sec:related_work}

Our work lies within three literature strands: smart predict-and-optimize, domain-specific learning, and learn-to-rank.

\noindent\textbf{Smart predict-and-optimize.}
Standard predict-then-optimize approaches (e.g.,~\cite{shahabikargar2014predicting}) typically minimize prediction error (MSE), ignoring downstream decision impact.
The SPO framework~\cite{elmachtoub2022smart} addresses this by minimizing decision regret directly, but its non-convexity necessitates surrogates like SPO+.
While extensions exist---SPO Trees~\cite{elmachtoub2020decisiontrees} for interpretability, relaxation-based methods for knapsack~\cite{Mandi2020}, or RL-based constrained optimization~\cite{Silvestri2024}---they often assume deterministic parameters or struggle with nonlinear scheduling dynamics.
In contrast, our framework directly exploits the critical-decision structure of polynomial-time rules, enabling stable, differentiable learning for complex scheduling objectives.

\noindent\textbf{Semi- and domain-specific SPO.}
Semi-SPO~\cite{Yang2023Semi,Yan2020Semi} and domain-specific methods for transport~\cite{tian2023}, manufacturing~\cite{Wang2024Refinery}, and energy~\cite{Alrasheedi2024Microgrid} employ specialized losses to improve performance.
However, these objectives typically lack theoretical guarantees of optimality.
By contrast, our surrogate is provably consistent: it converges exactly to the true decision regret as the smoothing parameter $\lambda \to 0$ (see Technical Appendix).

\noindent\textbf{Learn to Rank.}
Learn-to-rank (LTR) methods like RankNet~\cite{burges2005learning}, ListWise~\cite{cao2007learning}, and BPR~\cite{rendle2009bpr} also utilize sigmoid-based penalties.
However, standard LTR losses optimize generic ranking metrics (e.g., AUC, NDCG) rather than the actual scheduling objective.
Our approach adapts the LTR mechanism but weights each decision by its precise contribution to the objective (SCT or makespan), ensuring the model minimizes the relevant operational cost.

\section{Conclusion}
\label{sec:conclusion}

This paper introduced a surrogate-based framework for predict-and-optimize that exploits the critical-decision structure of polynomial-time algorithms.
We instantiated this framework for single-machine SCT and two-machine flow shop problems, deriving smooth surrogates that provably converge to decision regret.
Experiments confirm that this approach yields robust schedules even under high noise, outperforming state-of-the-art baselines by significant margins in both synthetic benchmarks and a real-world hospital case study.
Future work will extend this decision-aware paradigm to complex multi-stage scheduling and broader combinatorial optimization tasks.

\bibliographystyle{named}
\bibliography{mybibfile}

\newpage
\newpage
\appendix

\section{Technical Appendix}
\label{sec:appendix}

In this appendix, we analyze the theoretical properties of the general surrogate loss introduced in Section~\ref{sec:framework}.
Recall that the surrogate is defined as:
\[
L_{\mathrm{surr}}(\omega)
=
\sum_{d \in \mathcal{K}}
\phi_d(\theta^\star)\,
\sigma\!\left(
\frac{-m_d(\omega;x,\theta^\star)}{\lambda}
\right).
\]
The following properties hold for any problem instantiation (including Problems 1 and 2), provided the decision scores $s_d$ (and thus $m_d$) are differentiable with respect to the model parameters $\omega$.

\begin{property}[Differentiability and smooth gradients]
\label{prop:differentiability}
The surrogate loss \(L_{\mathrm{surr}}\) is infinitely differentiable with respect to $m_d$.
The derivative of the sigmoid function component is:
\[
\frac{\partial \sigma(u)}{\partial u} = \sigma(u)(1-\sigma(u)),
\]
where $u = -m_d/\lambda$.
\end{property}
\noindent Differentiability ensures stable gradient-based optimization using standard backpropagation, avoiding the nondifferentiability of the raw regret.

\begin{property}[Tunable sensitivity via \(\lambda\)]
The steepness of the decision boundary is controlled by the temperature parameter \(\lambda>0\).
\end{property}
\begin{proof}
The gradient magnitude is scaled by $1/\lambda$.
Smaller \(\lambda\) values sharpen the sigmoid transition around $m_d=0$, increasing sensitivity to small correctness margins (i.e., decisions near the boundary) and approaching a step function.
\end{proof}
\noindent The hyperparameter \(\lambda\) thus allows fine-tuning the trade-off between optimization stability (large $\lambda$) and approximation accuracy (small $\lambda$).

\begin{property}[Decision-weighted penalization]
\label{prop:order}
The loss penalizes incorrect critical decisions in proportion to their impact $\phi_d$.
\end{property}
\begin{proof}
Consider a critical decision $d$.
If the decision is correct ($m_d > 0$), the argument to the sigmoid is negative, $\sigma(\cdot) < 0.5$, and the penalty is small (approaching 0 as $m_d$ increases).
If the decision is incorrect ($m_d < 0$), the argument is positive, $\sigma(\cdot) > 0.5$, and the penalty is large (approaching $\phi_d$ as $m_d$ decreases).
Thus, the model focuses on correcting decisions with high impact $\phi_d$ (e.g., large SCT swaps or Johnson makespan costs).
\end{proof}

\begin{theorem}[Convergence to regret]
\label{thm:lambda_impact}
As \(\lambda \to 0\), the surrogate loss \(L_{\mathrm{surr}}\) converges to the exact decision regret $R(\hat{\theta},\theta^\star)$ (up to a constant shift or scaling depending on the specific problem definition).
\end{theorem}
\begin{proof}
As \(\lambda \to 0\), the term $\sigma(-m_d/\lambda)$ converges to the indicator function $\mathbb{I}[m_d < 0]$ (assuming $m_d \neq 0$).
The loss becomes:
\[
\lim_{\lambda \to 0} L_{\mathrm{surr}} = \sum_{d \in \mathcal{K}} \phi_d(\theta^\star) \cdot \mathbb{I}[\text{decision } d \text{ is incorrect}].
\]
By construction (Step 3a and 3c), $\phi_d$ represents the cost contribution of an incorrect decision $d$.
In Problem 1, this sum is exactly the SCT regret (sum of $R_{i,j}$ for misordered pairs).
In Problem 2, it approximates the makespan regret via the aggregated Johnson swap costs.
\end{proof}





\section{Additional results}

\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{new_plot/linearDataset_problem1.png}
\caption{Comparison of SPO+, Rank Loss, and the proposed surrogate method on \emph{linear} datasets of size $10000$. SCT error (logarithmic scale) relative to the optimal schedule is shown.}
\label{fig:nonLinear_dataset_1_machine_problem}
\end{figure}





\end{document}


