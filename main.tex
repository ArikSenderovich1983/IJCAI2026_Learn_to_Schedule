\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in

% IJCAI 2026 style
\usepackage{ijcai26}

% Recommended IJCAI packages
\usepackage{times}
\usepackage{soul}
\usepackage{url}
\usepackage{multirow}
\usepackage[hidelinks]{hyperref}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{booktabs}
\usepackage{paralist}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{color}
\usepackage[switch]{lineno}

\usepackage{xcolor}
\newcommand\btext[1]{{\color{blue}{#1}}}

\linenumbers
\urlstyle{same}

% PDF metadata required by IJCAI (title/authors intentionally omitted)
\pdfinfo{
/TemplateVersion (IJCAI.2026.0)
}

% Theorem-like environments
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{definition}{Definition}
\newtheorem{property}{Property}

\newenvironment{problem}[1]
  {\vspace{\baselineskip}\noindent\textbf{Problem} (#1).\itshape}
  {\par}

% Title and authors (placeholders to be updated)
\title{Surrogate-Based Smart Predict and Schedule}

\author{Anonymous}
% \author{
%   First Author$^1$\and
%   Second Author$^2$\And
%   Third Author$^3$\\
%   \affiliations
%   $^1$Affiliation One\\
%   $^2$Affiliation Two\\
%   $^3$Affiliation Three\\
%   \emails
%   first.author@example.com,
%   second.author@example.com,
%   third.author@example.com
% }

\begin{document}

\maketitle

\begin{abstract}
Task scheduling under uncertainty is a fundamental challenge in artificial intelligence and operations research, with applications in manufacturing, logistics, cloud computing, and healthcare.
Smart predict-and-optimize (SPO) methods address this challenge by learning predictive models that directly minimize decision regret, but in practice they struggle with non-differentiable objectives and the discrete nature of optimal scheduling rules.
We propose a surrogate-based framework for smart predict-and-schedule that views polynomial-time scheduling algorithms,
such as shortest-processing-time (SPT), earliest-due-date (EDD), FIFO, and Johnson's rule,
as collections of critical decisions, and attaches to each decision a smooth sigmoid-based penalty weighted by its contribution to the scheduling objective.
We instantiate this framework on two classical problems: (i) single-machine scheduling with the sum of completion times (SCT) objective, where misordered job pairs are weighted by their SCT increase, and (ii) the two-machine flow shop with makespan minimization, where misclassified groups and misordered jobs are weighted by the corresponding Johnson swap costs.
Experiments on synthetic SCT benchmarks and a real-world outpatient scheduling dataset from a cancer hospital show that our surrogate-based approach consistently outperforms the baselines across a vast majority of problem instances.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

Scheduling involves allocating limited resources to tasks over time to optimize objectives such as minimizing the sum of completion times (SCT), makespan, or weighted tardiness~\cite{baker2018principles,pinedo2022scheduling}.
It is a foundational problem in artificial intelligence and operations research, with applications in manufacturing, logistics, cloud computing, and healthcare.
Classical approaches typically assume that task parameters (e.g., processing times, release dates, due dates) are known and deterministic, enabling the use of efficient algorithms and priority rules such as SPT, EDD, FIFO, or Johnson's rule.
In reality, however, these parameters are uncertain and must be inferred from historical data.
This mismatch between deterministic models and stochastic environments motivates the development of data-driven decision-making methods that explicitly account for uncertainty in both prediction and optimization.

Smart predict-and-optimize (SPO) methods offer one such paradigm~\cite{elmachtoub2022smart}.
Rather than learning to predict task parameters in isolation, SPO couples prediction with downstream optimization by minimizing empirical \emph{decision regret}: the difference between the objective value of the decision induced by learned predictions and that of the optimal decision under the true parameters.
Despite their conceptual appeal, SPO methods face two major challenges in practice.
First, the regret objective is often non-differentiable and highly non-convex, making gradient-based learning difficult.
Second, even when differentiable surrogates such as SPO+ are available~(\citeauthor{elmachtoub2020decisiontrees}~\citeyear{elmachtoub2020decisiontrees}), they may be poorly aligned with the structure of specific scheduling rules and can exhibit unstable training behaviour, especially when small changes in predictions lead to large changes in the optimal schedule.

In this paper, we develop a surrogate-based framework that addresses these challenges for a broad class of polynomial-time scheduling algorithms.
The key idea is to exploit the structure of known optimal dispatching rules and view them as finite sets of \emph{critical decisions} (e.g., pairwise orderings or group assignments) that fully determine the resulting schedule.
For each decision, we construct a smooth sigmoid-based penalty whose argument is a signed decision score and whose weight reflects the local impact of that decision on the scheduling objective (e.g., SCT increase or makespan increase).
This yields a differentiable ``ReLU-over-decision'' surrogate that penalizes costly misdecisions while remaining largely neutral on confidently correct ones, providing stable gradients that focus on ambiguous or high-impact decisions.

Our primary case study is the single-machine SCT minimization problem, where we introduce a sigmoid-based surrogate that directly approximates regret by weighting misordered task pairs by their contribution to SCT.
We further show how the same principles extend to a two-machine flow shop with makespan minimization, where the deterministic optimal policy is given by Johnson's rule and the surrogate weights misgroupings and misorderings by the corresponding Johnson swap costs.
Across both problems, the resulting surrogates retain the interpretability of classical algorithms while enabling flexible learning with neural networks.

To validate our approach, we conduct extensive experiments on synthetic and real-world datasets.
On synthetic instances of the SCT problem, our surrogate consistently outperforms SPO+, logistic rank-loss, and mean-squared-error baselines, especially under high noise and large duration variability.
On a large-scale outpatient scheduling dataset from a cancer hospital, our method achieves the lowest relative SCT error across most months, demonstrating robustness in a noisy, feature-limited environment.

Our contributions can be summarized as follows:
\begin{enumerate}
    \item We propose a surrogate-based framework for smart predict-and-schedule that views polynomial-time scheduling rules (e.g., SPT, EDD, FIFO, Johnson's rule) as sets of critical decisions and derives differentiable sigmoid-based losses at the decision level.
    \item We instantiate this framework on two classical scheduling problems: (i) single-machine SCT minimization and (ii) two-machine flow shop makespan minimization, deriving problem-specific surrogates that weight each decision by its contribution to SCT or makespan.
%    \item We provide theoretical guarantees for the SCT surrogate, including differentiability and convergence to regret as the sigmoid sharpness parameter tends to zero, and show how algorithmic structure (e.g., Johnson's rule and associated swap costs) guides surrogate design in the flow shop setting.
    \item We empirically evaluate our approach on synthetic SCT benchmarks and a real-world hospital scheduling dataset, demonstrating consistent improvements over state-of-the-art SPO, learn-to-rank, and predict-then-optimize baselines.
\end{enumerate} The remainder of the paper is organized as follows.
Section~\ref{sec:framework} introduces our general predict-and-schedule framework.
Sections~\ref{sec:problem1} and~\ref{sec:flowshop} instantiate this framework for single-machine SCT minimization and two-machine flow shop makespan minimization, respectively.
Section~\ref{sec:evaluation} presents experimental results on synthetic benchmarks, followed by a real-world case study in patient scheduling in Section~\ref{sec:case_study}.
We discuss related work in Section~\ref{sec:related_work} and conclude in Section~\ref{sec:conclusion}.

\section{Surrogate-Based Predict-and-Optimize}
\label{sec:framework}

This section makes the paper's core premise explicit: many classical
\emph{polynomial-time scheduling rules} can be expressed as collections of
\emph{critical decisions} (comparisons, threshold tests, and group assignments)
that fully determine the resulting schedule.
We use this view to derive smooth, decision-level surrogate losses for
smart predict-and-schedule.
While the same idea can sometimes be transferred to other decision problems, we
do not claim universal applicability beyond settings where such a decomposition
is available.

\subsection{Problem Setting}

We consider a scheduling instance with $n$ jobs.
Each job $i$ has observed features $x_i \in \mathbb{R}^p$ and an unknown
parameter vector $\theta_i^\star$ (e.g., processing time, due date, or release
time).
Let $\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$ denote the
collection of true job parameters.
A schedule (or sequencing decision) is denoted by $\pi \in \Pi$, where $\Pi$
is the set of feasible schedules for the environment under study.
The resulting objective value under the true parameters is $C(\pi;\theta^\star)$,
where $C$ may represent, for example, sum of completion times or makespan.

The learning task is to learn
$\hat{\theta} = f_\omega(x)$ (with parameters $\omega$) by minimizing
the regret of using $\pi(\hat{\theta})$ instead of the
optimal solution, namely
\begin{equation}
\label{eq:regret-general}
R(\hat{\theta},\theta^\star)
:=
C(\pi(\hat{\theta});\theta^\star)
-
C(\pi(\theta^\star);\theta^\star),
\end{equation}
which is generally non-differentiable with respect to~$\omega$.
The framework 
below addresses this challenge by exploiting problem structure.

\noindent\textbf{Step 1: Identify Unknown Parameters (or Decision-Relevant Scores).}
For each job $i$, define the unknown parameter vector $\theta_i^\star$ governing
its contribution to the optimization problem (e.g., processing times, due dates,
or machine-dependent durations).
Let a dataset
$\mathcal{D}=\{(x_j,\theta_j^\star)\}_{j=1}^N$ be given, consisting of past
observations from which a predictor $f_\omega$ can be trained.
In some problems, it is convenient for $f_\omega$ to predict not the raw
parameters $\theta$ directly, but a set of \emph{decision-relevant scores} that
parameterize the critical decisions of the deterministic algorithm (Step~2).

\noindent\textbf{Step 2: Identify a Deterministic Polynomial-Time Counterpart.} Many optimization problems become tractable when $\theta^\star$ is known.
Suppose that, for known parameters $\theta$, the deterministic variant admits a
polynomial-time algorithm $\mathcal{A}$ that returns an optimal decision:
\[
\pi(\theta) = \mathcal{A}(\theta).
\]
Examples include single-machine scheduling problems where sorting rules are optimal, and
two-machine flow shops solved by Johnson’s rule, two problems which we tackle in this paper.
Such algorithms typically reveal a structural decomposition
$\mathcal{A}(\theta)$ that induces partitions, rankings, or threshold decisions.
This structure is key for constructing differentiable surrogates.

\noindent\textbf{Step 3: Derive a Smooth Surrogate from $\mathcal{A}$.} The deterministic algorithm $\mathcal{A}$ induces a discrete mapping from
parameters~$\theta$ to decisions~$\pi$.
To train a neural network via gradient
descent, we replace this mapping with a differentiable surrogate loss
$L_{\mathrm{surr}}$ that approximates the regret in
(\ref{eq:regret-general}).
The construction follows three principles:

\paragraph{(a) Structural decomposition.}
Let $\mathcal{A}$ determine a schedule through a finite set of \emph{critical
decisions} $\mathcal{K}$, such as:
(i) pairwise precedence comparisons (e.g., SPT/EDD/FIFO-style ordering
decisions), (ii) threshold tests, or (iii) group assignments (e.g., Johnson's
partition into $G_1$ and $G_2$).
Crucially, the elements of $\mathcal{K}$ need not be job pairs: in some rules
they are per-job classification decisions, and in others they are comparisons.

\paragraph{(b) Sigmoid relaxations.}
For each critical decision $d \in \mathcal{K}$, define a signed \emph{decision
score} $s_d(\omega;x)$ produced by the predictor, such that the sign of
$s_d$ encodes the model's preferred outcome for $d$ (e.g., ``$i$ before $j$''
or ``job $i \in G_1$'').
We then replace the hard, non-differentiable decision indicator by a smooth
sigmoid approximation.
To ensure the surrogate penalizes the \emph{wrong} outcome (rather than
encouraging a fixed sign), we orient each decision score using the true
parameters.
Specifically, define a \emph{signed correctness margin}
$m_d(\omega;x,\theta^\star)$ such that $m_d>0$ when the model agrees with the
ground-truth decision for $d$ (with margin) and $m_d<0$ otherwise.
In other words, $s_d$ is the model's \emph{raw} score for decision $d$, while
$m_d$ is the same score \emph{re-oriented} so that its sign always encodes
\emph{correctness}. Concretely, if under $\theta^\star$ the correct outcome for
$d$ corresponds to ``$s_d>0$,'' then $m_d=s_d$; if the correct outcome
corresponds to ``$s_d<0$,'' then $m_d=-s_d$.
(For example, if $s_d = \hat{\theta}_i - \hat{\theta}_j$ represents a precedence score where positive means ``$i$ before $j$,'' but the ground truth requires $j$ before $i$, we set $m_d = -s_d$ so that $m_d > 0$ signifies the correct decision.)
We then use the smooth misclassification indicator
\[
\sigma\!\left( -\frac{m_d(\omega;x,\theta^\star)}{\lambda} \right),
\]
where $\lambda>0$ controls sharpness around the boundary, $s_d=0$.

\paragraph{(c) Weighted aggregation.}
The surrogate loss is assembled as a weighted sum over critical decisions:
\begin{equation}
\label{eq:general-surrogate}
L_{\mathrm{surr}}(\omega)
:=
\sum_{d \in \mathcal{K}}
\phi_d(\theta^\star)\,
\sigma\!\left(
\frac{-m_d(\omega;x,\theta^\star)}{\lambda}
\right),
\end{equation}
where $\phi_d(\theta^\star)\ge 0$ measures the impact of deciding $d$ incorrectly
on the scheduling objective (e.g., SCT increase or makespan increase).
As $\lambda \to 0$, the surrogate approaches a hard penalty on incorrect
decisions, while for $\lambda>0$ it remains smooth and trainable with gradient
descent.

\noindent\textbf{Step 4: Train the Prediction Model.} The neural network $f_\omega$ is trained by minimizing the surrogate loss:
\[
\omega^\star
:= 
\arg\min_{\omega}
L_{\mathrm{surr}}(\omega).
\]
At inference time, the model produces either predicted parameters
$\hat{\theta}=f_{\omega^\star}(x)$ or decision-relevant scores that determine
the critical decisions; these are passed into the polynomial-time algorithm:
\[
\hat{\pi}
:=
\mathcal{A}(\hat{\theta}).
\]
We note that this approach can, in principle, be applied beyond scheduling to routing, assignment, and other
combinatorial optimization problems in which the deterministic case is
tractable and structurally interpretable.
In this paper, we show an instantiation for two well-known scheduling problems
under uncertainty.

% \subsection{Implications for Scheduling Problems}
% \label{sec:framework-scheduling}

% Scheduling problems are a natural fit for the proposed framework because many
% deterministic scheduling objectives admit polynomial-time optimal rules with
% explicit structure.
% In such cases, the set $\mathcal{K}$ of critical decisions is not an
% abstraction: it corresponds to the comparisons and assignments performed by the
% rule itself.
% Importantly, $\mathcal{K}$ is \emph{problem- and rule-dependent} and does not
% have to be a set of job pairs.

% \paragraph{Examples of critical-decision sets.}
% \begin{itemize}
%     \item \textbf{SPT for $1\|\sum C_j$:}
%     $\mathcal{K}$ can be taken as pairwise precedence decisions
%     $d=(i,j)$ encoding ``$i$ should precede $j$'', induced by comparisons
%     of processing times.
%     \item \textbf{EDD for due-date objectives:}
%     $\mathcal{K}$ can similarly be precedence decisions based on due dates.
%     \item \textbf{FIFO in single-server queues:}
%     $\mathcal{K}$ encodes precedence decisions induced by arrival-time order.
%     \item \textbf{Johnson's rule for $F2\|C_{\max}$:}
%     $\mathcal{K}$ naturally decomposes into (i) per-job group-assignment
%     decisions (whether job $i$ belongs to $G_1$ or $G_2$) and
%     (ii) within-group ordering decisions.
%     The former are \emph{not} pairwise comparisons.
% \end{itemize}

% \paragraph{Why decision-level weights matter.}
% Weights $w_d(\theta^\star)$ are essential: they determine which mistakes the
% learning algorithm prioritizes.
% For SCT, swapping two jobs far apart in the sequence can have much larger
% impact than swapping two adjacent jobs; for Johnson's rule, misclassifying a
% job close to the boundary $p_{i1}=p_{i2}$ may be less harmful than
% misclassifying a job with a large margin, and some within-group misorderings
% increase makespan substantially more than others.

\subsection{Running Example: Outpatient Scheduling}
\label{sec:framework-running-example}
Consider a stylized outpatient clinic with a single exam doctor.
Patients $i=1,\dots,n$ arrive randomly with known appointment times and
uncertain exam durations.
Depending on the operational objective, a deterministic policy might implement
FIFO (serve in order of arrival), an EDD-like rule (serve those with earlier appointment times first), or 
an SPT-like rule (serve those with shorter predicted exams
first) as a proxy for minimizing waiting or completion-time objectives.

In this setting, a critical decision could be a precedence relation (``serve
patient $i$ before patient $j$''), but it could also be a per-patient
classification decision (``patient $i$ belongs to the short-visit group''),
depending on the scheduling rule used.
The surrogate in Eq.~\eqref{eq:general-surrogate} penalizes incorrect or ambiguous
decisions through $\sigma(-m_d/\lambda)$ and uses $\phi_d(\theta^\star)$ to reflect
their downstream impact (e.g., increase in total waiting time or SCT).
This connects directly to the hospital case study in
Section~\ref{sec:case_study}, where our learning objective is designed to
improve the resulting patient sequencing rather than pointwise duration
accuracy.

In the remainder of the paper, we instantiate the framework on two canonical
problems: single-machine SCT minimization (Problem~1) and two-machine flow shop
makespan minimization (Problem~2).
For each, we derive a problem-specific surrogate by specifying (i) the set of
critical decisions $\mathcal{K}$ and (ii) the weights $\phi_d$.

\section{Problem 1: Single-Machine Scheduling}
\label{sec:problem1}
We now instantiate the four-step framework of Section~\ref{sec:framework} for the
single-machine sum of completion times (SCT) objective, where the processing times are unknown.
The deterministic counterpart is solved by the shortest-processing-time (SPT)
rule; we derive a smooth, decision-level surrogate that targets the pairwise
precedence decisions induced by SPT and weights each potential misordering by
its SCT impact.

\noindent\textbf{Step 1: Identify Unknown Parameters.}
In this problem, the unknown parameter for each task $i$ is its processing time
$y_i>0$. In the notation of Section~\ref{sec:framework}, we write
$\theta_i^\star := y_i$ and $\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$.
We observe features $x_i\in\mathbb{R}^p$ and learn a predictor
$\hat{\theta}_i = f_\omega(x_i)$ from a dataset
$\mathcal{D} = \{(x_j, \theta_j^\star)\}_{j=1}^N$ (equivalently, $\hat{y}_i=\hat{\theta}_i$).

\noindent\textbf{Step 2: Deterministic Polynomial-Time Counterpart.} We consider the following single-resource scheduling setting: a resource is assigned to process $n$ tasks (e.g., jobs scheduled for a given day).
All $n$ tasks are assumed to be available at the beginning of the scheduling period, but their processing times are unknown.
The resource is non-idling, working continuously until all tasks are completed.
The objective is to find a task sequencing that minimizes the sum of completion times (SCT).
When the true durations $y_1, \ldots, y_n$ are known, the optimal sequence follows the shortest processing time first (SPT) heuristic, arranging tasks in ascending order of their durations~\cite{pinedo2022scheduling}.
Equivalently, letting $\theta=(\theta_1,\dots,\theta_n)$ denote processing
times, the deterministic algorithm is
\(
\pi(\theta)=\mathcal{A}_{\mathrm{SPT}}(\theta)
\),
where $\mathcal{A}_{\mathrm{SPT}}$ sorts tasks by increasing $\theta_i$.

% In realistic settings, however, the actual task durations are unknown.
% Instead, historical data with features correlated with task durations are available.
% This historical data can be used to predict task durations and subsequently schedule the tasks using the SPT rule.
% However, prediction errors can lead to suboptimal schedules.

% Adopting a supervised learning framework, we assume the following model~\cite{hastie2009elements}:
% \begin{equation} \label{eq:master_ppm}
% y_i = f(x_i) + \epsilon_i,
% \end{equation}
% where $f$ is an unknown deterministic function, and $\epsilon_i$ is a random noise term with mean $0$ and variance $\sigma^2$ (identically distributed across tasks).

A straightforward approach is the predict-then-optimize paradigm~\cite{Mandi2020},
in which $f_\omega$ is learned by minimizing empirical mean squared error (MSE):
\begin{equation}
\omega^\star_{\mathrm{MSE}}
=
\arg\min_{\omega} \sum_{j=1}^{N} \bigl(f_\omega(x_j) - y_j\bigr)^2,
\end{equation}
The resulting model predicts durations $\hat{y}_i=f_{\omega^\star_{\mathrm{MSE}}}(x_i)$,
and the optimization phase schedules tasks by sorting predicted durations (SPT).
In Section~\ref{sec:framework} notation, this corresponds to computing
$\hat{\theta}_i=f_{\omega^\star_{\mathrm{MSE}}}(x_i)$ and then
$\hat{\pi}=\mathcal{A}_{\mathrm{SPT}}(\hat{\theta})$.

In other words, prediction errors are unavoidable, but not all impact the task order in scheduling.
MSE treats all errors the same, even though only those that change task order impact the SCT objective.
Thus, minimizing MSE may not effectively reduce SCT, as it overlooks the distinction between harmless and harmful errors.

To better understand this, consider a sequencing of tasks where the task placed in position \(k\) has duration \(y_k\).
The total SCT can be expressed as:
\begin{equation}
\mathrm{SCT} = \sum_{k=1}^n (n+1-k) \, y_k.
\end{equation}

Swapping two tasks at positions \(i < j\) alters their contribution by:
\begin{align}
R_{i,j} &= \big[(n{+}1{-}i)\, y_j + (n{+}1{-}j)\, y_i\big] \nonumber \\
       &\quad - \big[(n{+}1{-}i)\, y_i + (n{+}1{-}j)\, y_j\big] \nonumber \\
       &= (j - i)(y_j - y_i).
\end{align}

A pair \((i,j)\) is said to be \emph{misordered} if \(y_i < y_j\) but the schedule places \(y_i\) after \(y_j\), leading to an increase in SCT of \((j-i)(y_j - y_i)\).
Clearly this conditional error, which represents the actual cost of mispredicting task durations, has a different structure from the MSE, which represents the incurred cost of mispredicting task durations.
To solve this problem, we aim to find a loss function for the prediction phase, different from MSE, that minimizes the actual cost of mispredicting task durations.

%\subsection{Regret Formulation for SCT}

Accordingly, we define the smart predict-and-schedule problem in terms of regret.

\begin{problem}{Regret minimization in SCT} \label{prob:problem1}
Find $f_\omega$ that minimizes the expected regret:
\begin{equation} \label{eq:smartsched}
L_{\text{regret}} = \sum_{\substack{\theta_i^\star < \theta_j^\star}} R_{i,j} \cdot \max(0, \text{sign}(f_\omega(x_i) - f_\omega(x_j))).
\end{equation}
\end{problem} For example, consider two tasks \(i\) and \(j\) with true durations \(y_i < y_j\).
If \(f_\omega(x_i) > f_\omega(x_j)\), the tasks are misordered, increasing the SCT.
The regret-based loss directly targets such misorderings by reducing their probability.
This means that even large prediction errors may be tolerated if they are symmetric, regardless of their impact on task ordering.
In contrast, regret-based models focus explicitly on getting the order right, yielding better scheduling decisions even when prediction accuracy is imperfect. Yet, directly optimizing regret is challenging due to non-differentiability and
the combinatorial nature of ordering tasks~\cite{elmachtoub2022smart}.
We therefore derive a differentiable surrogate loss that targets the critical
pairwise precedence decisions of SPT and weights each decision by its SCT
impact.

\noindent\textbf{Step 3: Derive a Smooth Surrogate from SPT.}  The critical decisions for SPT are pairwise precedence comparisons.
For a pair $(i,j)$, define the decision score
\(
s_{i,j}(\omega;x)= \hat{\theta}_i-\hat{\theta}_j = f_\omega(x_i)-f_\omega(x_j)
\),
whose sign encodes the model's preference.
When $\theta_i^\star<\theta_j^\star$ (i.e., $y_i<y_j$), the correct order is
$i$ before $j$, and a misordering occurs
when $s_{i,j}(\omega;x)>0$.
In the framework notation, take $\mathcal{K}=\{d=(i,j): i<j\}$, $s_d=s_{i,j}$,
and orient by the ground truth:
\(
m_d(\omega;x,\theta^\star)=-s_{i,j}(\omega;x)
\)
for $\theta_i^\star<\theta_j^\star$, so $m_d>0$ iff the order is correct.
With $\phi_d(\theta^\star)=R_{i,j}$, Eq.~\eqref{eq:general-surrogate} gives the term
$R_{i,j}\sigma(s_{i,j}/\lambda)$.
We therefore approximate the hard misordering indicator with 
\(\sigma(s_{i,j}(\omega;x)/\lambda)\), weighted by the SCT impact of the swap.

The proposed sigmoid-based loss penalizes misordered task pairs, encouraging the model to predict task durations aligned with their true ordering.
The empirical sigmoid loss is defined as:
\begin{equation}
L_{\text{sigmoid}}
\;=\;
\sum_{\substack{\theta_i^\star < \theta_j^\star}}
  R_{i,j}\,
  \sigma\!\Bigl( \tfrac{f_\omega(x_i) - f_\omega(x_j)}{\lambda} \Bigr),
\end{equation}
where \(\sigma(x) = \tfrac{1}{1+e^{-x}}\) is the sigmoid function, and \(\lambda>0\) controls the steepness around misordered predictions.
A larger \(\lambda\) smooths transitions, while a smaller \(\lambda\) sharpens sensitivity to misorderings.

By minimizing the empirical sigmoid loss, the learned model \(f_\omega\) is encouraged to satisfy \(f_\omega(x_j) > f_\omega(x_i)\) whenever \(\theta_j^\star > \theta_i^\star\).
Formally:
\[
\omega^\star
\;=\;
\arg\min_{\omega}
  L_{\text{sigmoid}}(\omega),
\]
Thus, training adjusts \(f_\omega\) to minimize the number and severity of misordered pairs, aligning predictions with true task durations.
When \(f_\omega\) preserves correct orderings, the sigmoid term remains near zero, driving \(L_{\text{sigmoid}}\) downward.

\noindent\textbf{Step 4: Train and Infer with SPT.} At inference time, given a new instance with features $\{x_i\}_{i=1}^n$, we
compute $\hat{\theta}_i=f_{\omega^\star}(x_i)$ and return
$\hat{\pi}=\mathcal{A}_{\mathrm{SPT}}(\hat{\theta})$, i.e., the SPT schedule
obtained by sorting tasks by $\hat{\theta}_i$ in ascending order.

% \subsubsection{Properties of the sigmoid-based surrogate}

% To show the usefulness of the sigmoid-based surrogate loss function for predict and schedule, we need to show that it is differentiable and approximates the regret in the SCT problem.

% The non-differentiability of the regret loss in Equation~\ref{eq:smartsched} is caused by the use of \(\max(0, \text{sign}(x))\), effectively a \(\text{ReLU}(\text{sign}(x))\) operation that is non-differentiable at \(x=0\).
% To solve the non-differentiability problem, we replace this with the sigmoid function \(\sigma(x)\) as a smooth approximation, enabling gradient-based optimization.
% Several properties of the sigmoid-based surrogate support its effectiveness:

% \begin{property}[Differentiability and smooth gradients]
% \label{prop:differentiability}
% The surrogate loss \(L_{\text{sigmoid}}\) is infinitely differentiable.
% The derivative of the sigmoid function is:
% \[
% \sigma'(u) = \sigma(u)(1-\sigma(u)).
% \]
% \end{property}
% \noindent Differentiability ensures stable gradient-based optimization throughout training, which allows us to train a neural network to solve
% the scheduling problem via an SPO-like method.

% \begin{property}[Tunable sensitivity via \(\lambda\)]
% The steepness of the decision boundary is controlled by \(\lambda>0\).
% \end{property}
% \begin{proof}
% The derivative \(\sigma'(u)\) is maximized near \(u=0\).
% Smaller \(\lambda\) values sharpen the sigmoid, increasing sensitivity to small misorderings.
% \end{proof}
% \noindent The hyperparameter \(\lambda\) thus offers a mechanism to fine-tune model responsiveness to near-boundary predictions.
% Higher $\lambda$
% yields low penalty for misorderings, while low values of $\lambda$
% push the objective to converge to Equation~\ref{eq:smartsched}.

% \begin{property}[Order sensitivity and penalization]
% \label{prop:order}
% The sigmoid loss penalizes misordered task pairs.
% \end{property}
% \begin{proof}
% For tasks \(i\) and \(j\) where \(y_j > y_i\), the loss contribution is:
% \[
% (j-i)(y_j-y_i)\,\sigma\!\Bigl(\tfrac{\hat{f}(x_i) - \hat{f}(x_j)}{\lambda}\Bigr).
% \]
% Correctly ordered pairs (\(\hat{f}(x_j) > \hat{f}(x_i)\)) yield negative inputs to \(\sigma\), resulting in near-zero penalties.
% Incorrectly ordered pairs (\(\hat{f}(x_i) > \hat{f}(x_j)\)) yield positive inputs, maximizing the penalty.
% \end{proof}
% \noindent As \(\lambda\to\infty\), all penalties converge to a uniform value, diminishing order sensitivity.

% \begin{property}[Sensitivity to small misorderings]
% \label{prop:sensitivity}
% The sigmoid loss penalizes near-boundary cases where \(\hat{f}(x_i) \approx \hat{f}(x_j)\).
% \end{property}
% \begin{proof}
% When \(\hat{f}(x_i) \approx \hat{f}(x_j)\), the input to the sigmoid approaches zero, yielding:
% \[
% \sigma(0) = 0.5.
% \]
% Thus, pairs with uncertain ordering are still penalized, encouraging the model to separate predictions more clearly.
% \end{proof}

% Finally, we present a convergence guarantee:

% \begin{theorem}[Convergence to regret loss]
% \label{thm:lambda_impact}
% The surrogate loss \(L_{\text{sigmoid}}\) converges to the regret loss \(L_{\text{regret}}\) as \(\lambda \to 0\).
% \end{theorem}
% \begin{proof}
% As \(\lambda \to 0\), the scaled differences \((\hat{f}(x_i)-\hat{f}(x_j))/\lambda\) tend toward \(\pm\infty\), and the sigmoid function \(\sigma(u)\) converges to a step function:
% \[
% \sigma(u) \to 
% \begin{cases}
% 1, & u > 0, \\
% 0, & u \leq 0,
% \end{cases}
% \]
% thus recovering the original regret loss.
% \end{proof}
% \noindent These properties position the sigmoid-based surrogate as a natural fit for learning-based scheduling under uncertainty.

% \subsubsection{Limitations of the sigmoid-based loss}

% While effective for single-machine SCT minimization, several limitations remain.
% First, the method has not been extended to multi-machine or distributed scheduling scenarios.
% Handling task dependencies, release times, or resource constraints would require significant modifications.
% Second, the hyperparameter \(\lambda\) critically influences model performance.
% Improper selection may cause either unstable training (if \(\lambda\) is too small) or diminished order sensitivity (if \(\lambda\) is too large), necessitating careful hyperparameter tuning.
% Third, pairwise loss computation scales quadratically with the number of tasks, which may become computationally expensive for large-scale instances.
% Although sampling techniques can mitigate this, further work is needed to improve scalability. 
% Finally, the underlying deterministic scheduling problem must be solvable in polynomial time; otherwise, training becomes computationally infeasible, as exact solutions used in the learning process are not efficiently obtainable.

% Addressing these limitations is an important direction for future work, with the goal of broadening the applicability of surrogate-based scheduling methods to more complex and large-scale environments.

\section{Problem 2: Flow Shop Scheduling}
\label{sec:flowshop}

The surrogate framework developed in Section~\ref{sec:framework} naturally extends
to other scheduling problems whose optimal deterministic policies admit rule-based
structural characterizations.
In this section, we demonstrate this by considering
the classical two-machine flow shop scheduling problem with makespan minimization,
denoted $F2\|C_{\max}$, for which the optimal policy is given by Johnson’s rule.
However, we consider the case where the processing times on the two machines are unknown. 
We show how to construct a smooth surrogate loss that mimics the structure of
the optimal rule while remaining differentiable and suitable for gradient-based
learning.

\noindent\textbf{Step 1: Identify Unknown Parameters.}
In the $F2\|C_{\max}$ setting, the unknown parameters for each job $i$ are its
two processing times on machines $1$ and $2$. In the notation of
Section~\ref{sec:framework}, let
$\theta_i^\star := (p_{i1},p_{i2})$ and
$\theta^\star := (\theta_1^\star,\dots,\theta_n^\star)$.

\noindent\textbf{Step 2: Deterministic Polynomial-Time Counterpart.} In the $F2\|C_{\max}$ setting, each job $i$ has two true processing times 
$(p_{i1}, p_{i2})$, one for each machine.
Johnson’s rule partitions all jobs into
two sets:
\[
G_1 = \{ i : p_{i1} < p_{i2} \}, 
\qquad
G_2 = \{ i : p_{i1} \ge p_{i2} \},
\]
orders $G_1$ in ascending $p_{i1}$, orders $G_2$ in descending $p_{i2}$, and 
concatenates the two sequences.
Consequently, the optimal sequence is determined
by (i) the correct group assignment of each job and (ii) the correct ordering 
within each group.
Equivalently, for known processing times $\theta$, the deterministic optimum is
\(
\pi(\theta)=\mathcal{A}_{\mathrm{J}}(\theta)
\),
where $\mathcal{A}_{\mathrm{J}}$ is Johnson's rule.

When processing times are unknown and must be predicted from features $x_i$, we
follow the Section~\ref{sec:framework} view and predict \emph{decision-relevant
scores} that parameterize the critical decisions of $\mathcal{A}_{\mathrm{J}}$.
Concretely, each job $i$ is mapped to two scalar scores
\[
(\hat{d}_i, \hat{s}_i) = f_\omega(x_i)=:\hat{\theta}_i,
\]
where $\hat{d}_i \in \mathbb{R}$ is a \emph{group score} indicating whether the
job should belong to $G_1$ or $G_2$, and $\hat{s}_i \in \mathbb{R}$ is a
\emph{sortable score} used to determine the job’s relative position \emph{within}
its assigned group.
The predicted sequence then follows the structure of Johnson’s rule:
\begin{enumerate}
    \item Assign each job to $\hat{G}_1$ if $\hat{d}_i < 0$ and to $\hat{G}_2$ otherwise.
    \item Sort $\hat{G}_1$ by increasing $\hat{s}_i$.
    \item Sort $\hat{G}_2$ by decreasing $\hat{s}_i$.
\end{enumerate}

This parameterization separates the discrete grouping decision from the within-group ranking
decision, reflecting the decomposition inherent in Johnson’s optimal policy.
At inference time, we apply the same deterministic structure,
$\hat{\pi}=\mathcal{A}_{\mathrm{J}}(\hat{\theta})$, using $\hat{\theta}_i=(\hat{d}_i,\hat{s}_i)$.

\noindent\textbf{Step 3: Derive a Smooth Surrogate from Johnson's Rule.} To train the model, we define a smooth surrogate loss consisting of two components:
(1) a penalty for incorrect \emph{group assignment}, and
(2) a penalty for incorrect \emph{within-group ordering}.
Both components rely on sigmoidal approximations of indicator functions, as in
Section~\ref{sec:framework}.

\smallskip
\noindent\textbf{Instantiation of $(\mathcal{K}, s_d, m_d, \phi_d)$ for Johnson's rule.}
Let $\mathcal{K}=\mathcal{K}_{\mathrm{group}}\cup\mathcal{K}_{\mathrm{order}}$
with group decisions $d=i$ and ordering decisions $d=(i,j)$.
For $d=i$, set $s_d=\hat{d}_i$, $m_d=\hat{d}_i d_i$ with $d_i=p_{i1}-p_{i2}$, and
$\phi_d=|d_i|$.
For $d=(i,j)$, set $\phi_d=\Delta_{i,j}$ and use sortable scores:
in $G_1$ (true $p_{i1}<p_{j1}$) take $s_d=\hat{s}_i-\hat{s}_j$ and $m_d=-s_d$;
in $G_2$ (true $p_{i2}>p_{j2}$) take $s_d=\hat{s}_j-\hat{s}_i$ and $m_d=-s_d$.
Then each term in $L_{\mathrm{group}}$ and $L_{\mathrm{order}}$ matches
Eq.~\eqref{eq:general-surrogate}.

\paragraph{Group assignment surrogate.}
For each job $i$, the true group indicator satisfies
\[
d_i = p_{i1} - p_{i2},
\qquad
i \in G_1 \iff d_i < 0.
\]
Incorrect assignment occurs when the predicted sign of $\hat{d}_i$ differs from the
true sign of $d_i$.
We define the group surrogate loss as
\begin{equation}
L_{\mathrm{group}}
:= 
\sum_{i} 
w_i \,
\sigma\!\left( -\frac{\hat{d}_i\, d_i}{\lambda} \right),
\label{eq:group-loss}
\end{equation}
where $\sigma$ is the sigmoid function, $\lambda>0$ controls smoothness, and
$w_i = |d_i|$ weights mistakes according to the severity of misclassification
(the farther a job is from the decision boundary $p_{i1} = p_{i2}$, the more 
important it is to assign it correctly).
The term in~\eqref{eq:group-loss} is
small when $\hat{d}_i$ has the correct sign with sufficient margin, and close to
1 otherwise.

\paragraph{Within-group surrogate.}
Conditioned on correct group membership, the regret of the flow shop policy arises
from misordering jobs within $G_1$ or $G_2$.
For two jobs $i,j$:
\begin{itemize}
    \item If $i,j \in G_1$ and $p_{i1} < p_{j1}$, then $i$ should precede $j$.
    \item If $i,j \in G_2$ and $p_{i2} > p_{j2}$, then $i$ should precede $j$.
\end{itemize}
To align the surrogate with makespan regret, we weight each potential swap by
its impact on completion time.
For two jobs $i$ and $j$ on machines $1$ and $2$, let
\begin{equation}
T_{i,j} = p_{i1} + \max(p_{i2},p_{j1}) + p_{j2},
\end{equation}
\begin{equation}
T_{j,i} = p_{j1} + \max(p_{j2},p_{i1}) + p_{i2},
\end{equation}
and define the incremental cost of placing $j$ before $i$ instead of the
correct order as
\begin{equation}
\Delta_{i,j} = T_{j,i} - T_{i,j}.
\end{equation}
We then set the within-group surrogate to
\begin{equation}
\label{eq:order-loss}
\resizebox{0.95\linewidth}{!}{$
\displaystyle
L_{\mathrm{order}}
:=
\sum_{\substack{i,j \in G_1 \\ p_{i1} < p_{j1}}}
\Delta_{i,j}\, \sigma\!\Big( \tfrac{\hat{s}_i - \hat{s}_j}{\lambda} \Big)
 +
\sum_{\substack{i,j \in G_2 \\ p_{i2} > p_{j2}}}
\Delta_{i,j}\, \sigma\!\Big( \tfrac{\hat{s}_j - \hat{s}_i}{\lambda} \Big)
$}\,.
\end{equation}
As in the SCT surrogate, the sigmoid penalizes misordered pairs (i.e., cases where
$\hat{s}_i > \hat{s}_j$ despite $i$ being correctly ordered before $j$), with 
penalties scaled by the corresponding increase in makespan $\Delta_{i,j}$.

\paragraph{Combined surrogate and properties.}
The full surrogate loss for Johnson’s rule is the simple additive combination
of group and ordering components:
\begin{equation}
\label{eq:johnson-loss}
L_{\mathrm{Johnson}}
:=
L_{\mathrm{group}}
+
L_{\mathrm{order}}.
\end{equation}
By construction, $L_{\mathrm{Johnson}}$ is infinitely differentiable in the
network parameters, and jobs whose misclassification or misordering has a
larger impact on the makespan (larger $|d_i|$ or $\Delta_{i,j}$) receive
larger weights.
As $\lambda \to 0$, the sigmoids in~\eqref{eq:group-loss} and
~\eqref{eq:order-loss} approach hard indicators of incorrect group assignment
and within-group ordering, so that $L_{\mathrm{Johnson}}$ converges to a
piecewise-constant approximation of the true makespan regret induced by
Johnson's rule.

\noindent\textbf{Step 4: Train and Infer with Johnson's Rule.}
We train $f_\omega$ by minimizing the surrogate $L_{\mathrm{Johnson}}$.
At inference time, given a new instance with features $\{x_i\}_{i=1}^n$, we
compute $(\hat{d}_i,\hat{s}_i)=f_{\omega^\star}(x_i)$ and construct the schedule
using the three-step Johnson-style procedure above (partition into
$\hat{G}_1,\hat{G}_2$, sort within each group, then concatenate).


\section{Evaluation}
\label{sec:evaluation}

This section details the empirical evaluation on synthetic datasets of the proposed approach for the single-machine SCT problem (Problem~1) and the Flow Shop Scheduling problem (Problem~2).
We first describe the experimental setup, including dataset generation, benchmark methods, implementation details, and evaluation metrics.
Next, we outline the experimental procedure for solving the scheduling problem and compare our method against existing baselines.
Finally, we present the main experimental results and discuss the applicability and scalability of our approach.

\subsection{Experimental Setup}

Experiments were conducted on synthetically generated datasets to evaluate the performance of the sigmoid-based surrogate loss under a range of scheduling scenarios.
The experiments systematically varied data generation models, noise levels, uncertainty level on task duration, and benchmark comparisons.

\paragraph{Datasets.}

We constructed two synthetic datasets using linear and nonlinear functions to simulate varying complexity levels.
This setup offers full control over noise and duration variability, allowing us to isolate the effect of surrogate loss choice.
In the absence of established benchmarks, these two datasets support systematic evaluation.
\begin{itemize}
    \item \emph{Linear model:} \( f(x) = \mathbf{xw} \), where \(\mathbf{w}\) is a randomly generated weight vector, and \(\mathbf{x}\) consists of features uniformly sampled from \([0, 1]\).
    
    \item \emph{Nonlinear model (Problem~2):} A nonlinear combination is computed as:
    \[
    g(x) = 3x_1^2 + 4.0\sin(2\pi x_2) + 3x_3x_4 + 2x_5^3,
    \]
    where \(x_1, \dots, x_5\) are uniformly sampled features.
    This specific structure introduces smooth nonlinearities, feature interactions, and periodic components, capturing diverse patterns typical of real-world systems.

    \item \emph{Nonlinear model (Problem~2):}
    To generate a suitable dataset for the $F2|C_{\max}$ problem, we define the durations of activities on both machines $m_1$ and $m_2$. Specifically, we define $m_1(\mathbf{x})$ and $m_2(\mathbf{x})$, which internally contain the function $g(\mathbf{x})$, as defined previously, and produce two distinct values in such a way as to ensure a balanced probability of assigning jobs to groups $G_1$ and $G_2$ (see Section~\ref{sec:flowshop}).
    \[
    \begin{aligned}
    m_1(\mathbf{x}) &= g(\mathbf{x}) + 0.3\, x_1 - 0.2\, x_3, \\
    m_2(\mathbf{x}) &= g(\mathbf{x}) - 0.25\, x_2 + 0.4\, x_4 .
    \end{aligned}
    \]

\end{itemize}

The functions were chosen to ensure that the learning task remains nontrivial, requiring the model to capture both local and global feature dependencies, while still being interpretable and reproducible.

o ensure strictly positive durations, constants of $100$ and $500$ were added to the final task durations for the Problem~1 and Problem~2 datasets, respectively. Finally, gaussian noise with standard deviation $\eta$ was added to simulate uncertainty.

\paragraph{Benchmark methods.}

We compared our method with two predict-and-optimize approaches, \emph{SPO+} and the $MSE$, as well as with a learn-to-rank (LTR) surrogate loss.
\emph{SPO+} is a convex surrogate loss designed for predict-and-optimize tasks \cite{elmachtoub2022smart}, which focuses predictions on minimizing decision regret.
In contrast, the \emph{logistic rank loss} is an LTR surrogate that penalizes incorrect pairwise orderings based on their difference, without relying on the specifics of the scheduling problem.
For each job pair $(i,j)$
we define the surrogate loss as $\sigma(\Delta_{ij})$ where in the Problem~1 $\Delta_{ij}$ is defined as 
$(f_\omega(x_j) - f_\omega(x_i))$ while for Problem~2
as $\min(\hat{p}_{i1}, \hat{p}_{j2}) -\min(\hat{p}_{j1}, \hat{p}_{i2})$.

\paragraph{Implementation details.}
The experiments were implemented in Python. Specifically, each baseline was trained using the same two-hidden-layer neural network architecture with the PyTorch library and the same number of iterations. Datasets were generated according to the described models, with varying noise levels $\eta$, to evaluate the models’ robustness to prediction uncertainty. Each dataset was normalized and split into 70\% training, 10\% validation, and 20\% test subsets. 

To reduce training time, we employ a pairwise sampling strategy rather than comparing all possible pairs of elements. This approach is sufficient to learn the relative ordering, as illustrated in Figure~\ref{fig:pairwaise_number}.

\paragraph{Evaluation metric.}
Models were evaluated on the test set by comparing the SCT and Makespan achieved predicted job orderings against those of the true optimal order, with results averaged over ten runs.
The optimal schedule is represent and SPT and Johnson schedule under true processing times for Problem~1 and ~2, respectively.


%We expect the Johnson-aligned surrogate in Section~\ref{sec:flowshop} to outperform baselines, particularly under high noise, by directly encoding the structure of the deterministic optimal policy.


\begin{figure}[t]
    \centering
    \includegraphics[width=0.45\textwidth]{new_plot/analysis_number_of_pairs.png}
    \caption{}
    \label{fig:pairwaise_number}
\end{figure}


\subsection{Results}


\begin{table}[t]
\centering
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{lcccccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{6}{c}{Noise Level} \\
                         & 0 & 2 & 4 & 6 & 8 & 10 \\
\midrule
MSE     & 0.576 & 0.363 & 0.359 & 0.701 & 0.706 & 1.132 \\
Rank Loss  & 0.225 & 0.284 & 0.356 & 0.494 & 0.647 & 0.976 \\
Regret Loss & \textbf{0.209} & \textbf{0.222} & \textbf{0.270} & \textbf{0.402} & \textbf{0.622} & \textbf{0.954} \\
SPO+ & 29.135 & 13.419 & 6.607 & 35.705 & 14.961 & 25.287 \\
\bottomrule
\end{tabular}}
\caption{SCT errors across with linear dataset with different noise level. Size $10000$.}
\label{tab:linear}
\end{table}


\begin{table}[t]
\centering
\resizebox{0.95\columnwidth}{!}{
\begin{tabular}{lcccccc}
\toprule
\multirow{2}{*}{Method} & \multicolumn{6}{c}{Noise Level} \\
                         & 0 & 2 & 4 & 6 & 8 & 10 \\
\midrule
MSE     & \textbf{2.264} & 2.778 & 2.780 & 2.679 & 3.126 & 3.623 \\
Rank Loss  & 2.614 & 2.748 & 2.753 & 3.017 & 3.192 & 3.544 \\
Regret Loss & 2.621 & \textbf{2.584} & \textbf{2.748} & \textbf{2.932} & \textbf{3.076} & \textbf{3.399} \\
SPO+ & 17.746 & 19.784 & 16.416 & 22.234 & 19.753 & - \\
\bottomrule
\end{tabular}}
\caption{SCT errors across with nonlinear dataset with different noise level. Size $10000$.}
\label{tab:linear}
\end{table}

Single machine, and then for 2-flowshop.



\section{Case Study: Patient Scheduling}
\label{sec:case_study}

We evaluate the proposed sigmoid-based surrogate loss on a real-world dataset
from \textit{DayHospital}, a U.S.\ cancer clinic. We describe the setting,
experimental protocol, and results.

\subsection{Case Description: Scheduling in DayHospital}

DayHospital is an outpatient clinic where patients arrive in the morning and
complete their visits later in the day. Visits may include a blood draw, an
examination, and chemotherapy infusion. We focus on the \emph{examination}
stage: doctors act as single-server machines and patients are jobs, with known
appointment (arrival) times but \emph{uncertain} exam durations.
The goal is to sequence exams to reduce congestion, as duration uncertainty can
create large downstream delays.

\subsection{Experimental Setup}

\paragraph{Dataset.} 
We used two months of operational data from \textit{DayHospital} (January and
November 2021). Data sources include:
\begin{itemize}
    \item \emph{Real-Time Location System (RTLS)} traces (3-second resolution).
    \item \emph{Appointment data} with scheduled times.
\end{itemize}
The dataset contains approximately 201,000 patient pathways. For each observed
patient at a station, we extract arrival, service-start, and service-completion
timestamps. After preprocessing, we focus on \textit{Exam} appointments. The
goal is to predict true durations \(y_i\) from features \(x_i\) in a way that
improves SCT under sequencing.

Feature vectors \(x_i\) include \texttt{floor\_id}, \texttt{scheduled\_time},
\texttt{department}, \texttt{scheduled\_duration\_min}, \texttt{diagnosis},
\texttt{appointment\_type}, and \texttt{link\_flag} (whether the exam is
followed by infusion).

To reflect deployment, we split by calendar time: for each month, train on the
first three weeks and evaluate on the fourth week (rolling-horizon generalization).

\paragraph{Benchmark methods.}
We evaluated our proposed approach against several benchmark loss functions commonly used in predictive scheduling tasks:
\begin{itemize}
    \item \emph{Rank Loss}: pairwise ranking via negative log-likelihood of correct comparisons.
    
    \item \emph{Mean Squared Error (MSE)}: standard regression loss; a predict-then-optimize baseline~\cite{shahabikargar2014predicting}.
    
    \item \emph{SPO+}: A convex surrogate loss for predict-and-optimize problems \cite{elmachtoub2022smart}, which approximates the scheduling regret through a differentiable upper bound on the decision loss.
\end{itemize}

\paragraph{Evaluation metric.}
As in the synthetic experiments, the evaluation objective for the real-world data is to minimize the SCT induced by the predicted task orderings.
For each model, predicted durations were used to sequence appointments, and the resulting SCT was computed based on the true durations.
To facilitate comparison across months and models, we report the \emph{relative SCT error}, defined as the difference between the predicted and optimal SCT values, normalized by the optimal SCT.
This reflects scheduling regret and matches the synthetic evaluation.

\subsection{Experimental Procedure}

Models are feedforward neural networks with two hidden layers (ReLU) and a
Softplus output. All methods use Adam (\(5\times10^{-3}\) learning rate,
\(10^{-4}\) weight decay) with early stopping. We train up to 2000 iterations
and evaluate relative SCT error every 50 steps by sequencing with predicted
durations \(\hat{y}_i\) and comparing SCT against the optimal order under true
durations \(y_i\). SPO+ uses a mini-batch surrogate with a differentiable LP.
All methods share the same splits and comparable model capacity.

\subsection{Results}

To assess the robustness of each method across time, we evaluated model performance on monthly datasets spanning January to December 2021.
Table~\ref{tab:monthly-sct} reports the final relative SCT error per method (ours is denoted SIG for sigmoid-based) in each month.
The bottom row presents the average SCT error across the year.
Our sigmoid-based method consistently outperforms baselines (except August 2021), achieving the lowest average error and demonstrating stable performance across different months.

\begin{table}[t]
\centering
\caption{Final relative SCT errors across months of 2021 for each method.
Average values: SPO+= 0.476, LTR= 0.338, MSE= 0.353, and SIG= \textbf{0.316}.}
\label{tab:monthly-sct}
\begin{tabular}{lcccccc}
\toprule
Method & Jan & Feb & Mar & Apr & May & Jun \\
\midrule
SPO+     & 0.48 & 0.56 & 0.53 & 0.53 & 0.52 & 0.42 \\
LTR      & 0.33 & 0.36 & 0.33 & 0.35 & 0.33 & 0.33 \\
MSE      & 0.35 & 0.38 & 0.36 & 0.35 & 0.34 & 0.34 \\
Sigmoid  & \textbf{0.31} & \textbf{0.34} & \textbf{0.33} & \textbf{0.33} & \textbf{0.30} & \textbf{0.31} \\
\midrule
Method & Jul & Aug & Sep & Oct & Nov & Dec \\
\midrule
SPO+     & 0.48 & 0.38 & 0.40 & 0.49 & 0.42 & 0.50 \\
LTR      & 0.33 & \textbf{0.28} & 0.34 & 0.32 & 0.37 & 0.38 \\
MSE      & 0.33 & 0.31 & 0.34 & 0.36 & 0.37 & 0.41 \\
SIG      & \textbf{0.30} & 0.29 & \textbf{0.31} & \textbf{0.29} & \textbf{0.33} & \textbf{0.35} \\
\bottomrule
\end{tabular}
\end{table}

As a representative example, Figure~\ref{fig:real-data-jan} shows the relative
SCT error over training iterations for January 2021.

\begin{figure}[t]
    \centering
    \includegraphics[width=0.5\textwidth]{LossComparison_Jan.png}
    \caption{Relative SCT error during training on the real-world Exam scheduling dataset for January 2021.
    The sigmoid-based regret loss consistently achieves lower SCT error compared to Rank Loss, MSE Loss, and SPO+.}
    \label{fig:real-data-jan}
\end{figure}

Overall, the sigmoid-based surrogate achieves the lowest SCT error. Rank Loss is
competitive early but plateaus higher; MSE underperforms, confirming that
prediction accuracy alone is insufficient; SPO+ converges but stabilizes at
higher error.

\section{Related Work}
\label{sec:related_work}

Task scheduling, a key focus in AI and operations research, involves estimating task durations and using decision-making algorithms to schedule tasks.
This paper explores data-driven approaches for scheduling under task uncertainty. 

\paragraph{Smart predict-and-optimize.}
Traditionally, machine learning is used to predict task durations, which are then used to solve scheduling problems (e.g.,~\cite{shahabikargar2014predicting}).
However, traditional methods often overlook the impact of predictions on decision-making, as they use loss functions like MSE that do not consider the scheduling problem. 
The SPO framework~\cite{elmachtoub2022smart} addresses this by using an SPO loss function that evaluates decision error.
However, the non-convex and discontinuous nature of the SPO loss poses challenges, leading to the development of the surrogate SPO+ loss function.
While effective, SPO assumes deterministic task parameters and struggles with non-linear scenarios.
Several extensions of SPO have been proposed to deal with these limitations and with specific problems.
SPO Trees (SPOTs)~\cite{elmachtoub2020decisiontrees} train decision trees under the SPO framework, providing interpretable models with reduced complexity.
However, they may not generalize well to noisy, non-linear scheduling scenarios.
Applied to large-scale problems like knapsack and energy-cost scheduling~\cite{Mandi2020}, SPO-relax uses relaxation-based oracles to reduce computational costs while maintaining decision quality.
It assumes reliable oracles and focuses on linear objectives.
UNIFY~\cite{Silvestri2024} integrates ML and constrained optimization for multi-stage decision-making under uncertainty.
It supports robust decisions but relies on reinforcement learning and virtual parameters, requiring problem-specific configurations.
Demirovic et al.~\cite{Demirovic2019} explored techniques for minimizing regret in the knapsack problem, highlighting the trade-offs between complexity and performance in combinatorial settings.

\paragraph{Semi- and domain-specific SPO.}
Semi-SPO approaches (e.g.,~\cite{Yang2023Semi,Yan2020Semi}) also use loss functions that are based on the outcome measurements from the optimization step.
These outcome measurements are often chosen to work well in specific domains.
Unlike SPO loss functions, semi-SPO loss functions are not derived from the regret measurement, and consequently cannot be proven to lead to an optimal solution.

Other domain-specific SPO techniques have been proposed, e.g., for transport planning~\cite{tian2023}, factory planning~\cite{Wang2024Refinery}, and energy grid optimization~\cite{Alrasheedi2024Microgrid}.
Like semi-SPO, these use domain-specific loss functions that do not guarantee convergence to the 
true loss of the underlying problem.
Our work also approximates domain-specific loss, yet it provably converges 
to the actual loss function.

\paragraph{Learn to Rank.} 
Our surrogate loss function uses the sigmoid function, common in learn-to-rank (LTR) methods like RankNet~\cite{burges2005learning}, ListWise~\cite{cao2007learning}, and BPR~\cite{rendle2009bpr}.
Compared to these approaches, we introduce a loss function specifically designed to minimize SCT error, making it particularly suitable for scheduling tasks.

\section{Conclusion}
\label{sec:conclusion}

This paper introduced a surrogate-based framework for predict-and-optimize that leverages deterministic, polynomial-time algorithms to construct smooth learning objectives aligned with decision regret.
Within this framework, we developed sigmoid-based surrogates for two canonical scheduling problems under uncertainty: single-machine SCT minimization and two-machine flow shop makespan minimization.
For the SCT problem, we proved that the surrogate converges to the regret loss as the sharpness parameter tends to zero, and empirically demonstrated substantial improvements over predict-then-optimize, SPO+, and LTR baselines on both synthetic and real-world hospital scheduling data.

Our results highlight the value of decision-aware surrogates that redistribute prediction errors in a way that benefits downstream scheduling objectives, rather than focusing solely on pointwise accuracy.
The framework is particularly attractive for problems whose deterministic variants are tractable and structurally interpretable, enabling surrogates that faithfully mirror optimal policies.
Future work will extend our approach to more complex scheduling scenarios (e.g., multi-machine and job shop problems), complete the empirical study of the flow shop surrogate, and explore applications beyond scheduling, such as routing, matching, and resource allocation.

\bibliographystyle{named}
\bibliography{mybibfile}

\end{document}


